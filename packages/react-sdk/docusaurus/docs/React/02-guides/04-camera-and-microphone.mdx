---
id: camera-and-microphone
title: Camera & Microphone
description: Docs on the media manager
---

Handling audio and video devices in a web application means working with [`MediaStream`](https://developer.mozilla.org/en-US/docs/Web/API/MediaStream), [`MediaDeviceInfo`](https://developer.mozilla.org/en-US/docs/Web/API/MediaDeviceInfo) and other WebRTC API objects. We did our best to hide this complexity inside the `MediaDevicesProvider`. The easiest way to set up the provider is by using the [`StreamCall`](../../ui-components/core/stream-call), but it's also possible to use the `MediaDevicesProvider` directly.

## Camera management

### Call settings

The default state of the camera is determined by the call settings:

```typescript
const metadata = useCallMetadata();

metadata?.settings?.video.camera_default_on;
```

### Start-stop camera

```typescript
const localParticipant = useLocalParticipant();
const isVideoMute = !localParticipant?.publishedTracks.includes(
  SfuModels.TrackType.VIDEO,
);
const { toggleVideoMuteState } = useToggleVideoMuteState();

console.log(`Camera is ${isVideoMute ? 'off' : 'on'}`);
toggleVideoMuteState();
```

### List and select devices

```typescript
const { selectedVideoDeviceId, switchDevice } = useMediaDevices();
const videoDevices = useVideoDevices(); // This will prompt for camera access

console.log(`Current device: ${selectedVideoDeviceId}`);
console.log('Video devices: ', videoDevices);
switchDevice('videoinput', '<device id>');
```

### Lobby preview

Here is how to setup a video preview displayed before joining the call:

```typescript
const [stream, setStream] = useState<MediaStream>();
const {
  selectedVideoDeviceId,
  getVideoStream,
  initialVideoState,
  setInitialVideoState,
} = useMediaDevices();

const videoDevices = useVideoDevices();

useEffect(() => {
  if (!initialVideoState.enabled) return;

  getVideoStream({ deviceId: selectedVideoDeviceId })
    .then((s) => {
      setStream((previousStream) => {
        if (previousStream) {
          disposeOfMediaStream(previousStream);
        }
        return s;
      });
    })
    .catch((e) =>
      setInitialVideoState({
        ...DEVICE_STATE.error,
        message: (e as Error).message,
      }),
    );
  return () => {
    setStream(undefined);
  };
}, [
  initialVideoState,
  getVideoStream,
  selectedVideoDeviceId,
  setInitialVideoState,
  videoDevices.length,
]);
```

### Client-side settings

It's possible to preselect the camera device and its state. A potential use-case would be to apply the user's previous choices loaded from `localStorage`.

```tsx
export const App = () => {
  const call = /* ... */;

  return (
    <StreamCall call={call} mediaDevicesProviderProps={{
        initialVideoEnabled: true, // This will override the state from call settings
        initialVideoInputDeviceId: '...'
    }}>
      <MyUI />
    </StreamCall>
  );
};
```

## Microphone management

### Call settings

The default state of the microphone is determined by the call settings:

```typescript
const metadata = useCallMetadata();

metadata?.settings?.audio.mic_default_on;
```

### Start-stop microphone

```typescript
const localParticipant = useLocalParticipant();
const isAudioMute = !localParticipant?.publishedTracks.includes(
  SfuModels.TrackType.AUDIO,
);

console.log(`Mic is ${isAudioMute ? 'off' : 'on'}`);
const { toggleAudioMuteState } = useToggleAudioMuteState();
```

### List and select devices

```typescript
const { selectedAudioInputDeviceId, switchDevice } = useMediaDevices();
const audioInputDevices = useAudioInputDevices(); // This will prompt for microphone access

console.log(`Current device: ${selectedAudioInputDeviceId}`);
console.log('Audio devices: ', audioInputDevices);
switchDevice('audioinput', '<device id>');
```

### Client-side settings

It's possible to preselect the microphone device and its state. A potential use-case would be to apply the user's previous choices loaded from `localStorage`.

```tsx
export const App = () => {
  const call = /* ... */;

  return (
    <StreamCall call={call} mediaDevicesProviderProps={{
        initialAudioEnabled: true, // This will override the state from call settings
        initialAudioInputDeviceId: '...'
    }}>
      <MyUI />
    </StreamCall>
  );
};
```

## Speaker management

### Browser support

Selecting audio output device for the call [isn't supported by all browsers](https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/sinkId), this is how you can check the availability:

```typescript
const { isAudioOutputChangeSupported } = useMediaDevices();
```

### List and select devices

```typescript
const { selectedAudioOutputDeviceId, switchDevice } = useMediaDevices();
const audioOutputDevices = useAudioOutputDevices(); // This will prompt for microphone access

console.log(`Current device: ${selectedAudioOutputDeviceId}`);
console.log('Audio output devices: ', audioOutputDevices);
switchDevice('audiooutput', '<device id>');
```

### Speaker device volume

The speaker device volume can be set on the master level for all the participants as well as for a selected participant. The master audio output level is stored in `Call` state and can be retrieved using the `useMasterAudioOutputLevel` hook. The level for a specific participant should be retrieved per `StreamVideoParticipant.audioOutputLevel`.

The volume can then be set to SDK's `Audio` component:

```tsx
const CustomComponent = ({participant}: {participant: StreamVideoParticipant}) => {
  const masterAudioOutputLevel = useMasterAudioOutputLevel();
  const localParticipant = useLocalParticipant();

  return (
    <Audio
          muted={participant.isLocalParticipant}
          sinkId={localParticipant?.audioOutputDeviceId}
          key={participant.sessionId}
          audioStream={participant.audioStream}
          volume={participant?.audioOutputLevel ?? masterAudioOutputLevel}
        />
    );
}
```

There are two components bundled with the SDK, that allow us to control the audio output level:

1. [`ToggleAudioOutputButton`](../../ui-components/call/call-controls#toggleaudiooutputbutton) - toggles the value between 0 and 1
2. [`AudioOutputLevelSlider`](../../ui-components/call/call-controls#audiooutputlevelslider) - sets the decimal value in range 0 - 1



### Client-side settings

It's possible to preselect the speaker device. A potential use-case would be to apply the user's previous choices loaded from `localStorage`.

```tsx
export const App = () => {
  const call = /* ... */;

  return (
    <StreamCall call={call} mediaDevicesProviderProps={{
        initialAudioOutputDeviceId: '...'
    }}>
      <MyUI />
    </StreamCall>
  );
};
```

## Advanced

### Device unavailability

It may happen, that we would like to react to a situation, when there is no device of a given kind (audio, video) available. This can for example happen, when a laptop lid is closed. In that case we may want to disable the given device kind for the next time, when the lid is re-opened. That would for example lead to respecting user privacy with video being turned-off, even though before closing the lid it was turned on. The SDK provides the following hooks that will execute a callback when all the devices of a given kind are disconnected:

- `useOnUnavailableVideoDevices`
- `useOnUnavailableAudioInputDevices`
- `useOnUnavailableAudioOutputDevices`

:::info
The `useOnUnavailableVideoDevices` hook is used in a pre-build component [`VideoPreview`](../../ui-components/participants/video-preview). Even after video device reconnection, the video preview is not restarted automatically and has to be enabled back manually by a user.
:::

### Sound detection

An important topic related to media devices management is sound detection. A feature often needed in a call scenario (volume detection, speaking-while-muted notification). We can start detecting the audio input level changes using the utility function [`createSoundDetector`](https://github.com/GetStream/stream-video-js/tree/main/packages/client/src/helpers/sound-detector.ts). The function requires an instance of [`MediaStream`](https://developer.mozilla.org/en-US/docs/Web/API/MediaStream) object of type `audioinput` and attaches sound analysers to it. The `MediaStream` can be retrieved by the SDK's `getAudioStream` utility function. Then it periodically collects audio frequency data. We can access this data by providing the `onSoundDetectedStateChanged` callback function. The callback function will be passed and object of type [`SoundDetectorState`](https://github.com/GetStream/stream-video-js/tree/main/packages/client/src/helpers/sound-detector.ts) as argument. From the object we can extract the information about the audio level (`audioLevel`) or a more simplified general flag that tells us, whether sound was detected (`isSoundDetected`).

It is also possible to configure the data collection algorithm with the third [`options` parameter](https://github.com/GetStream/stream-video-js/tree/main/packages/client/src/helpers/sound-detector.ts).

The return value of [`createSoundDetector`](https://github.com/GetStream/stream-video-js/tree/main/packages/client/src/helpers/sound-detector.ts) function is a clean-up function that should be called, when a component, that uses sound detection is unmounted.
