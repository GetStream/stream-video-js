---
title: Livestream Tutorial
description: How to build a live stream experience using Stream's React Video SDKs
---

## Quickstart

In this quickstart, we'll build a live-streaming experience that is similar to Twitch.

- The live stream will run on Stream's Edge network of servers around the world
- We can use ultra-low latency ([WebRTC](https://webrtc.org/)) based livestreaming or [HLS](https://en.wikipedia.org/wiki/HTTP_Live_Streaming) (slight delay, but better buffering)
- We will go through the process of publishing the live stream from the browser
- Stream enables us to automatically scale to millions of viewers (no actions required from your side)
- We even show how to have multiple active participants in the live stream

The app that we are going to build will work in two modes: Host (presenter) and Viewer (audience).

The host will be able to publish the live stream and the viewers will be able to watch the live stream.
If you want to see a full-blown example, check out this [sample app.](https://github.com/GetStream/stream-video-js/tree/main/sample-apps/react/livestream-app)

Let's get started.

## Step 1 - Preparations

Before going into the code, let's make sure we have everything we need.

1. [Registered Stream account](https://getstream.io/try-for-free/)
2. Have an app created in the [Stream's dashboard](https://dashboard.getstream.io/) to obtain app API key and secret.
3. Initiate the project (you can follow our [introductory tutorial setup guide](../../tutorials/video-calling#set-up-for-success))
4. Have installed the Stream video and chat SDKs in the project:

```shell
npm install @stream-io/video-react-sdk
```

```shell
yarn add @stream-io/video-react-sdk
```

5. Have populated `.env` file in the project root

```shell
VITE_STREAM_API_KEY=<your_api_key>
# URL from which the JWT is requested
VITE_TOKEN_PROVIDER_URL=<your_token_provider_url>
```

## Step 2 - Set up the host mode

Hosts will communicate with each other in real-time.
For that purpose, we will use the SDK-provided `<StreamCall /`> component to establish a WebRTC-based call for the hosts.

:::note
In this tutorial, we will skip the details on how a `StreamVideoClient` can be set up. You can read more about it on the following page:
[Authenticating your Users](../../guides/client-auth/)
:::

In the code snippet provided, we establish a connection to the Stream Edge server as the live stream host. We then proceed to join the call and publish our audio and video content to the live stream.
In this example, we use the predefined [`<PaginatedGridLayout>`](../../ui-components/core/call-layout/#paginatedgridlayout) for the live stream.

If you prefer a more customized layout, you can build your own. See our article about [Building Custom Layouts.](../../ui-cookbook/video-layout/)

```tsx
import { useEffect, useState } from 'react';
import {
  Call,
  useCall,
  useCallCallingState,
  useMediaDevices,
  CancelCallButton,
  PaginatedGridLayout,
  StreamCall,
  StreamVideo,
  ToggleAudioPublishingButton,
  ToggleCameraPublishingButton,
} from '@stream-io/video-react-sdk';

// ... API key, provider, and user setup

export const HostApp = () => {
  const client = /* ... */;
  const [call, setCall] = useState<Call | undefined>(undefined);

  useEffect(() => {
    if (!client) {
      return;
    }
    setCall(client.call('livestream', callId));
  }, [callId, client]);

  useEffect(() => {
    if (!call) {
      return;
    }
    call.join({
      create: true,
      data: {
        // optionally, invite other hosts to the live stream
        members: [
          {
            user_id: connectedUser.id,
            role: 'host',
          },
        ],
      },
    });
  }, [call]);

  return (
    <StreamVideo client={client}>
      {call && (
        <StreamCall call={call}>
          <BackstageUI />
        </StreamCall>
      )}
    </StreamVideo>
  )
}

const BackstageUI = () => {
  const call = useCall();
  const callState = useCallCallingState();
  // useMediaDevices() hook provides you quick access to the Browser's MediaDevices API
  // and a few helper methods to manage your audio and video streams.
  const { publishVideoStream, publishAudioStream } = useMediaDevices();

  useEffect(() => {
    if (!call) return;
    if (callState === CallingState.JOINED) {
      // once the call is joined, publish the host's audio and video
      publishVideoStream();
      publishAudioStream();
    }
  }, [call, callState, publishAudioStream, publishVideoStream]);

  return (
    <>
      <BackstageHeader />
      // use a predefined layout from the SDK or build your own
      <PaginatedGridLayout />
      <BackstageControls />
    </>
  );
};

const BackstageControls = () => {
  return (
    <div className="backstage-controls">
      <ToggleAudioPublishingButton />
      <ToggleCameraPublishingButton />
      <CancelCallButton />
      // The implementation of this button is shown in the next step
      <ToggleLivestreamButton />
    </div>
  );
};

```

With this done, we have a fully functional livestream experience for the host.
The hosts can join the live stream, publish their audio and video, and invite other hosts to the live stream.

:::note
When the call is started, the livestreaming isn't enabled for the viewers yet.
We will see how to enable it in the next step.
:::

## Step 3 - Enable the live stream for the viewers

For simplicity, we are going to implement an additional button in the `BackstageControls` component that will enable the live stream for the viewers.

The button should be able to toggle the live stream on and off. For that purpose, we are going to use two utility hooks from the SDK:

- `useCall` and
- `useIsCallBroadcastingInProgress`

The `useCall` hook provides us with the current call object. This is useful when we want to access the call object from a component that is deep in the component tree with the `<StreamCall />` component as a predecessor.

On the other hand, the `useIsCallBroadcastingInProgress` hook gives us the current broadcasting state of the call. This is helpful when we want to show the current state of the live stream or build custom UI components or flows based on this call state.

The `call` instance itself provides two methods for starting and stopping the livestream:

- `call.startBroadcasting()` and
- `call.stopBroadcasting()`

Knowing all of this, let's write the code for the button:

```tsx
const ToggleLivestreamButton = () => {
  const call = useCall();
  const isBroadcasting = useIsCallBroadcastingInProgress();
  return (
    <Button
      onClick={() => {
        if (isBroadcasting) {
          call.stopBroadcasting();
        } else {
          call.goLive();
          call.startBroadcasting();
        }
      }}
    >
      {isBroadcasting ? 'Stop Stream' : 'Start Stream'}
    </Button>
  );
};
```

Remember to invoke `call.goLive()` to make the call active for all participants.

:::info

Starting and stopping a live stream for the viewers is an operation that takes a few seconds to complete.
It is a good practice to show a loading indicator while the operation is in progress.

There are two ways how we can do that:

- have a `useEffect` that would run whenever we have initiated a change in the broadcasting state of the call until the value of `isBroadcasting` toggles.
- attach an event listener to the call object and follow the delivery of `call.broadcasting_started` and `call.broadcasting_stopped` events. Read more about events [here.](../../advanced/events)

:::

## Step 4 - Set up the viewer mode

The viewer mode is very similar to the host mode. The only difference is that the viewer doesn't have to publish their audio and video to the live stream.

A viewer can join a live stream in two ways:

- WebRTC-based livestreaming (ultra-low latency), by using Stream Edge servers
- HLS-based livestreaming (slight delay, but better buffering), by using Stream CDN

### WebRTC-based livestreaming

For the WebRTC, we are going to use the same `<StreamCall />` component as in the host mode. The only difference is that we are going to use an anonymous user for the viewer.

:::caution

Anonymous users can't establish a WebSocket connection to our backend, therefore they are unable to receive any events from the call.
This means that the viewer won't know when the call starts or stops broadcasting.

To circumvent this limitation, the Viewer app should be able to be notified by the Host app or some other backend service when the call starts or stops broadcasting.
Alternatively, you can keep polling the backend for the current state of the call. For more details on this, see [Querying Calls.](../../guides/querying-calls)

:::

```tsx
import {
  Call,
  useCallCallingState,
  CallingState,
  LoadingIndicator,
  PaginatedGridLayout,
  StreamCall,
  StreamVideo,
} from '@stream-io/video-react-sdk';

// ... API key, provider, and user setup

export const ViewerApp = (props) => {
  const client = /* ... */;

  // `callId` needs to be provided from some party.
  // it is up to the developer to decide how to do that (prop, query param, etc.)
  const callId = props.callId;
  const [activeCall, setActiveCall] = useState<Call>();

  useEffect(() => {
    if (!callId) return;
    const call = client.call('livestream', callId);
    call.get().then(() => setActiveCall(call));
  }, [client, callId]);

  useEffect(() => {
    if (!activeCall) {
      return;
    }
    activeCall.join();
  }, [activeCall]);

  return (
    <StreamVideo client={client}>
      {call && (
        <StreamCall call={call}>
          <WebRTCLivestreamUI />
        </StreamCall>
      )}
    </StreamVideo>
  );
};

const WebRTCLivestreamUI = () => {
  const isJoined = useCallCallingState() === CallingState.JOINED;
  return (
    <>
      <ViewerHeader />
      // use any layout from the SDK or build your own
      <PaginatedGridLayout />
      // show a loading indicator while the call is joining
      {!isJoined && <LoadingIndicator />}
      <ViewerControls />
    </>
  );
};
```

### HLS-based livestreaming

For the HLS scenario, we are going to use one very popular library called `hls.js`.
HLS.js is a JavaScript library that implements an HTTP Livestreaming client. It relies on HTML5 video and MediaSource Extensions for playback.
You can read more about HLS.js [here.](https://github.com/video-dev/hls.js/)

For the HLS-based livestreaming, we are going to use a few components from the Stream Video SDK for React. However, instead using a pre-built layout,
we are going to set up the HLS.js library and use it to play the live stream.

In the example below, you will get familiar with the `useCallMetadata` hook.
This hook returns the metadata of the current call.
In our case, the metadata will contain the HLS playlist URL that we are going to use to play the live stream.

Compared to the WebRTC example, we would just replace the "UI" component with the following:

```tsx
import { ... } from '@stream-io/video-react-sdk';
import HLS from 'hls.js';

export const ViewerApp = () => {
  // pseudo-code for simplicity, see the previous example for the full code
  const client = /* ... */;
  const [activeCall] = client.queryCalls({...});
  return (
    <StreamVideo client={client}>
      {activeCall && <StreamCall call={activeCall}>
        <HLSLivestreamUI />
      </StreamCall>}
    </StreamVideo>
  )
}

export const HLSLivestreamUI = () => {
  // The HLS playlist URL is in call's metadata
  // we'll use the `useCallMetadata()` hook to get it
  const metadata = useCallMetadata();
  const hls_playlist_url = metadata?.egress.hls?.playlist_url;

  const [isPlaying, setIsPlaying] = useState(false);
  const videoRef = useRef<HTMLVideoElement>(null);
  useEffect(() => {
    if (!call || !hls_playlist_url) return;

    const hls = new HLS();
    hls.loadSource(hls_playlist_url);
    hls.attachMedia(videoRef.current);
  }, [call]);

  return (
    <>
      <ViewerHeader />
      // this is the video that HLS.js would use to playback the stream.
      <video autoPlay playsInline ref={videoRef} onPlay={() => setIsPlaying(true)} />

      {!isPlaying && <LoadingIndicator />}
      <ViewerControls />
    </>
  );
};
```

Having done this, we now have a fully functional live-streaming experience for the viewers based on HLS.

:::tip

For simplicity, a few things are omitted from the code snippet above. For the full-blown and working example,
check this Livestreaming sample app:

- [Livestream App source code](https://github.com/GetStream/stream-video-js/tree/main/sample-apps/react/livestream-app)
- [Livestream App live preview](https://video-react-livestream-app.vercel.app/)

:::

## Recap

It was fun to see just how quickly you can build a live-stream app for your hosts and viewers.
Please do let us know if you ran into any issues.
Our team is also happy to review your UI designs and offer recommendations on how to achieve it with Stream.

To recap what we've learned:

- You set up a call with `const call = client.call('livestream', '123')`
- The call type `livestream` controls which features are enabled and how permissions are set up
- The `livestream` by default enables `backstage` mode, and only allows admins and the creator of the call to join before the call goes live
- When you join a call, realtime communication is set up for audio & video streaming: `await call.join()`
- Call state `call.state` and helper state access hooks make it easy to build your own UI

We've used [Stream's Livestreaming API](https://getstream.io/video/livestreaming/),
which means calls run on a global edge network of video servers.
By being closer to your users the latency and reliability of calls are better.
The React SDK enables you to build in-app [video calling, audio rooms and livestreaming](https://getstream.io/video/) in days.

We hope you've enjoyed this tutorial and please do feel free to reach out if you have any suggestions or questions.
