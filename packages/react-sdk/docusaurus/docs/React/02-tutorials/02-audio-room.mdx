---
title: Audio Room Tutorial
description: How to build an audio room using Stream's video SDKs
---

import { TokenSnippet } from '../../../shared/_tokenSnippet.jsx';

In this guide, you'll build an audio room experience similar to Twitter Spaces / Clubhouse.

The code for the final result can also be found on GitHub, so if you're only interested in seeing the resulting code, go [here](https://github.com/GetStream/stream-video-js/tree/main/sample-apps/react/audio-rooms-tutorial).

:::note
For the sake of simplicity, the code provided in this guide may be simplified in certain situations. However, there will always be a link to the repository with the full code, so that you'll be able to have a look at that.
:::

Alright, let's get started. Creating this app will require the following steps:

1. Set up the project
2. Creating rooms via the API
3. Querying calls (with real-time updates)
4. Going live
5. Joining, leaving and ending a room
6. Managing speaking requests

### App preview
You can preview the Audio Rooms demo application by joining an audio room:

<TokenSnippet sampleApp='audio-rooms' displayStyle="join"/>

## Project setup and prerequisites

Make sure you have the following prerequisites checked:

1. [Registered Stream account](https://getstream.io/try-for-free/)
2. Have an app created in the [Stream's dashboard](https://dashboard.getstream.io/) to obtain app API key and secret.
3. Initiate the project (you can follow our [introductory tutorial setup guide](../../tutorials/video-calling#set-up-for-success))
4. Have installed the Stream video and chat SDKs in the project:

```shell
npm install @stream-io/video-react-sdk
```

```shell
yarn add @stream-io/video-react-sdk
```

With the basic setup of the project and the Stream SDK ready we can dive into the code.

### User authentication

The first important step is to initialize the Stream Video client. Therefore, we need an API key and a token provider.

<TokenSnippet sampleApp='audio-rooms' displayStyle="credentials"/>

Normally, you would store these values in your project's `.env` file. For the simplicity we include those values statically in the source as shown below. The credentials can then be passed to the `StreamVideoClient` constructor:

```tsx
import { useState } from 'react';
import { StreamVideo, StreamVideoClient } from '@stream-io/video-react-sdk';

import Room from './components/RoomPage';

const apiKey: string = ''; // The API key can be found in the Credentials section
const token: string = ''; // The Token can be found in the Credentials section
const userId: string = ''; // The User ID can be found in the Credentials section
const image: string = ''; // (Optional) The image URL, you would like to be displayed in the UI.
const roomId: string = ''; // The room ID we plan to join.

const user = {
  id: userId,
  name: userId,
  image,
};

const App = () => {
  const [client] = useState(
    () =>
      new StreamVideoClient({
        apiKey,
        token,
        user,
      }),
  );

  return (
    <div className="app-container">
      <StreamVideo client={client}>
        <Room roomId={roomId} />
      </StreamVideo>
    </div>
  );
};

export default App;
```


### Creating & loading the room

Now that we are done with the user authentication, we can start building the app. The first thing we'll do is to allow users to create an audio room where others can then join. We do this by creating a new `Call` instance and calling `getOrCreate` method on it:

```tsx
import { useCallback, useEffect, useState } from 'react';
import {
  Call,
  StreamCall,
  useConnectedUser,
  useStreamVideoClient,
} from '@stream-io/video-react-sdk';
import { RoomUI } from './RoomUI';

type RoomProps = {
  roomId: string;
};

function Room({ roomId }: RoomProps) {
  const client = useStreamVideoClient();
  const connectedUser = useConnectedUser();
  const [call, setCall] = useState<Call | undefined>();
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<Error | undefined>();

  const loadRoom = useCallback(async () => {
    if (!(client && connectedUser)) return;
    try {
      setLoading(true);
      // highlight-start
      const newCall = client.call('audio_room', roomId);
      await newCall.getOrCreate({
        data: {
          members: [{ user_id: connectedUser.id, role: 'admin' }],
          custom: {
            title: `${connectedUser.id}'s Room`,
            description: `Room created by ${connectedUser.id}.`,
            hosts: [connectedUser],
          },
        },
      });
      // highlight-end
      setCall(newCall);
    } catch (e) {
      setError(e as Error);
    } finally {
      setLoading(false);
    }
  }, [client, connectedUser, roomId]);

  useEffect(() => {
    loadRoom().catch((err) => {
      console.error(`Error loading room.`, err);
    });
  }, [loadRoom]);

  if (loading) {
    return <div className="loading-panel">Loading...</div>;
  }

  if (error) {
    return (
      <div className="error-panel">
        <h2>Error</h2>
        {error.message}
      </div>
    );
  }

  if (!call) {
    return null;
  }

  return (
    <StreamCall call={call}>
      <RoomUI loadRoom={loadRoom} />
    </StreamCall>
  );
}

export default Room;
```
We make sure the user that creates the room has `admin` rights and is listed in the `members` object.

We populate `custom` call data with the following payload:

:::note
We keep an array of user IDs called `speakerIds` in order to make it visible to all the room participants, who has been granted permission to speak. This array is populated once the participant is granted permission to speak.
:::

```ts
export type CustomCallData = {
  // provided when creating the room
  description?: string;
  // by default contains a single User - the room creator
  // will be displayed along with other speakers - separated from non-speakers
  hosts?: User[];
  // an array to keep track of participants, who were granted permission to speak
  speakerIds?: string[];
  // provided when creating the room
  title?: string;
};

export interface User {
  id: string;
  name: string;
  imageUrl: string;
}
```



:::note
It is important to load the call anew with each page visit so that all the subscriptions that handle the call state internally, are put in place. For example, if a call was previously left, the subscriptions are not in place anymore.
:::

### The room UI
The room UI should allow users to:

1. Control the room access
2. List speakers and listeners
3. Request permission to speak

### Controlling the room access
The calls of the type `audio_room` are created with restricted possibility to join the room.  In order users can join the room the host needs to set it live by calling  `call.goLive()`. The hosts are the users that have the permission `join-backstage`.

Once the room is live, the participants can join the room by simply calling `call.join()`. The room can be left by calling `call.leave()`. To return the room to backstage mode, hosts can invoke `call.stopLive()`. Stopping the room will kick all the participants out and can be performed only by the user with permission `end-call`. This permission will be again reserved to the call host.

All the mentioned operations are enabled in our app through the `RoomAccessControls` component. The render of buttons reserved for the hosts is controlled by the `Restricted` component:


```tsx
import {
  CallingState,
  OwnCapability,
  Restricted,
  useCall,
  useCallCallingState,
  useCallMetadata,
  useIsCallLive,
} from '@stream-io/video-react-sdk';

export const RoomAccessControls = () => {
  const call = useCall();
  const metadata = useCallMetadata();
  const callingState = useCallCallingState();
  const isLive = useIsCallLive();

  if (
    !call ||
    // The controls will not be shown. Instead, a lobby overlay will be presented.
    (callingState !== CallingState.JOINED && isLive) ||
    !!metadata?.ended_at
  )
    return null;

  const canJoin = ![
    CallingState.JOINING,
    CallingState.JOINED,
    CallingState.LEFT,
  ].includes(callingState);

  return (
    <div className="room-access-controls">
      {!isLive ? (
        <Restricted
          // highlight-next-line
          requiredGrants={[OwnCapability.JOIN_BACKSTAGE]}
          hasPermissionsOnly
        >
          <button
            className="room-access-controls-button"
            onClick={async () => {
              // highlight-next-line
              await call.goLive();
              if (canJoin) await call.join();
            }}
          >
            Go live{canJoin ? ' and join' : ''}!
          </button>
        </Restricted>
      ) : (
        <>
          <Restricted
            // highlight-next-line
            requiredGrants={[OwnCapability.END_CALL]}
            hasPermissionsOnly
          >
            <button
              className="room-access-controls-button"
              onClick={async () => {
                // highlight-start
                await call.stopLive();
                // leave the call to reset the Call state
                await call?.leave();
                // highlight-end
              }}
            >
              Stop room
            </button>
          </Restricted>
          <button
            className="room-access-controls-button"
            onClick={async () => {
              // highlight-next-line
              await call.leave().catch((err) => {
                console.error('Error leaving call', err);
              });
            }}
          >
            Leave Quietly
          </button>
        </>
      )}
    </div>
  );
};

```


The application introduces room lobby in form of overlay `RoomLobby` component. This is to give app users possibility to decide, when to enter the room. To determine, whether a room is live, we use `useIsCallLive` hook. We also rely on `Call` calling state to display informative text about the call connection state. The value is updated by `useCallCallingState` hook.

```tsx
import {
  Avatar,
  CallingState,
  useCall,
  useCallCallingState,
  useCallMetadata,
  useIsCallLive,
} from '@stream-io/video-react-sdk';

export const EndedRoomOverlay = () => {
  return (
    <div className="room-overlay">
      <p>This room has been terminated</p>
    </div>
  );
};

const CallingStateStatus: Record<string, string> = {
  [CallingState.RECONNECTING]: 'Trying to reconnect',
  [CallingState.RECONNECTING_FAILED]: 'Reconnect failed',
  [CallingState.OFFLINE]: 'You are offline',
  [CallingState.JOINING]: 'Joining the room...',
};

export const RoomLobby = () => {
  const call = useCall();
  // emits the latest Call calling state value
  // highlight-next-line
  const callingState = useCallCallingState();
  // changes to true once the call is set live by the host
  // highlight-next-line
  const isLive = useIsCallLive();

  if (!call) return null;

  if (Object.keys(CallingStateStatus).includes(callingState)) {
    return (
      <div className="room-overlay">
        <p>{CallingStateStatus[callingState]}</p>
      </div>
    );
  }

  return (
    <div className="room-overlay">
      {isLive && <p>The room is live.</p>}
      {!isLive && <RoomIntro />}
      <button
        disabled={!isLive}
        className="room-access-controls-button"
        onClick={async () => {
          // highlight-start
          await call.join().catch((err) => {
            console.log(err);
          });
          // highlight-end
        }}
      >
        Join
      </button>
    </div>
  );
};

const RoomIntro = () => {
  const metaData = useCallMetadata();
  const host = metaData?.custom.hosts[0];
  const hostName = host?.name ?? host?.id ?? 'Host';
  return (
    <div className="room-intro">
      <div className="room-host">
        <Avatar
          className="host-avatar"
          name={hostName}
          imageSrc={host?.imageUrl}
        />
        <h3>{hostName}</h3>
      </div>
      <p className="room-description">{metaData?.custom.description}</p>
      <p>The room isn't live. Please wait until the host opens it.</p>
    </div>
  );
};

```


### Managing speaking requests
Only the room hosts have default permission to speak (`send-audio`) during the live stream. The rest has to request a permission to speak. A permission to speak can be requested only, if this is [enabled for a given call in call settings](todo add link to enablement guide).

All the above is reflected in the `LiveRoomControls` component that:

- renders `ToggleMuteButton`, if the user has `send-audio` permission
- renders `RequestToSpeakButton` if the call settings allow to ask for permission
- renders the button to open the list of requests to speak if the user has permission `update-call-permissions` (the user can grant permission to speak).

:::important
Participants, that are not hosts have to request speaking permissions each time they (re)join a room.
:::


```tsx
import {
  CallingState,
  OwnCapability,
  StreamCallEvent,
  useCall,
  useCallCallingState,
  useCallMetadata,
  useConnectedUser,
  useHasPermissions,
  useLocalParticipant,
  useMediaDevices,
} from '@stream-io/video-react-sdk';
import { useEffect, useState } from 'react';
import type { CustomCallData } from '../types';

type OpenNotificationsButtonProps = {
  hasNotifications: boolean;
  openRequestsList: () => void;
};

type LiveRoomControlsProps = OpenNotificationsButtonProps;


export const LiveRoomControls = ({
  hasNotifications,
  openRequestsList,
}: LiveRoomControlsProps) => {
  const call = useCall();
  const callMetadata = useCallMetadata();
  const callingState = useCallCallingState();
  const connectedUser = useConnectedUser();
  const canSendAudio = useHasPermissions(OwnCapability.SEND_AUDIO);
  const canRequestSpeakingPermissions = call?.permissionsContext.canRequest(
    OwnCapability.SEND_AUDIO,
  );
  const { publishAudioStream, stopPublishingAudio, setInitialAudioEnabled } =
    useMediaDevices();

  const [isAwaitingAudioApproval, setIsAwaitingAudioApproval] = useState(false);

  // Determine, whether the current user has been promoted to speaker in the past by looking at Call's custom data
  const isSpeaker = (callMetadata?.custom as CustomCallData).speakerIds?.some(
    (id) => id === connectedUser?.id,
  );

  // highlight-start
  // Register an effect that will start publishing the user's audio, once permission to speak is granted
  useEffect(() => {
    if (!(call && connectedUser)) return;
    return call.on('call.permissions_updated', (event: StreamCallEvent) => {
      if (event.type !== 'call.permissions_updated') return;
      if (connectedUser.id !== event.user.id) return;
      if (event.own_capabilities.includes(OwnCapability.SEND_AUDIO)) {
        setInitialAudioEnabled(true);
        publishAudioStream();
      } else {
        stopPublishingAudio();
      }
    });
  }, [
    call,
    connectedUser,
    publishAudioStream,
    setInitialAudioEnabled,
    stopPublishingAudio,
  ]);
  // highlight-end

  // Don't wait for approval once the user has permission to speak
  useEffect(() => {
    if (canSendAudio) {
      setIsAwaitingAudioApproval(false);
    }
  }, [canSendAudio]);

  if (!call || callingState !== CallingState.JOINED) return null;

  const showMuteButton =
    canSendAudio || (canRequestSpeakingPermissions && isSpeaker);

  return (
    <div className="live-room-controls">
      <OpenNotificationsButton
        hasNotifications={hasNotifications}
        openRequestsList={openRequestsList}
      />
      {isAwaitingAudioApproval ? (
        <AwaitingApprovalIndicator />
      ) : showMuteButton ? (
        <ToggleMuteButton
          setIsAwaitingAudioApproval={setIsAwaitingAudioApproval}
        />
      ) : (
        <RequestToSpeakButton
          setIsAwaitingAudioApproval={setIsAwaitingAudioApproval}
        />
      )}
    </div>
  );
};

type AudioRequestApprovalProps = {
  setIsAwaitingAudioApproval: (isAwaiting: boolean) => void;
};

const ToggleMuteButton = ({
  setIsAwaitingAudioApproval,
}: AudioRequestApprovalProps) => {
  // ... implementation below ...
};

const RequestToSpeakButton = ({
  setIsAwaitingAudioApproval,
}: AudioRequestApprovalProps) => {
  // ... implementation below ...
};

const AwaitingApprovalIndicator = () => (
  // ... implementation below ...
);

const OpenNotificationsButton = ({
  hasNotifications,
  openRequestsList,
}: OpenNotificationsButtonProps) => (
  // ... implementation below ...
);
```

The logic of requesting speaking permission is as follows.

1. Request the permission to speak and observe the waiting-for-permission indicator

```tsx
import {
  OwnCapability,
  Restricted,
  useCall,
} from '@stream-io/video-react-sdk';
import {
  RaiseHandIcon,
} from './icons';

type AudioRequestApprovalProps = {
  setIsAwaitingAudioApproval: (isAwaiting: boolean) => void;
};

const RequestToSpeakButton = ({
  setIsAwaitingAudioApproval,
}: AudioRequestApprovalProps) => {
  const call = useCall();
  if (!call) return null;

  return (
    <Restricted requiredGrants={[OwnCapability.SEND_AUDIO]} canRequestOnly>
      <button
        className="icon-button"
        title="Request to speak"
        onClick={() => {
          setIsAwaitingAudioApproval(true);
          call.requestPermissions({
            permissions: [OwnCapability.SEND_AUDIO],
          });
        }}
      >
        <RaiseHandIcon />
      </button>
    </Restricted>
  );
};
````

2. The host who has permission to update other participants permissions can approve or dismiss the request. The controller API for speaker requests can be located into a hook we can call `useSpeakingRequests`:

```ts
import { useCallback, useEffect, useState } from 'react';
import {
  OwnCapability,
  PermissionRequestEvent,
  StreamCallEvent,
  useCall,
  useCallMetadata,
  useHasPermissions,
} from '@stream-io/video-react-sdk';

export const useSpeakingRequests = () => {
  const call = useCall();
  const metadata = useCallMetadata();
  const canUpdatePermissions = useHasPermissions(
    OwnCapability.UPDATE_CALL_PERMISSIONS,
  );
  const [isOpenRequestList, setIsOpenRequestList] = useState(false);

  const [speakingRequests, setSpeakingRequests] = useState<
    PermissionRequestEvent[]
  >([]);

  // To dismiss a speaking request in our case means to unmount it from the UI
  const dismissSpeakingRequest = useCallback(
    (speakingRequest: PermissionRequestEvent) => {
      const newRequests = speakingRequests.filter(
        (r) => r.user.id !== speakingRequest.user.id,
      );
      setSpeakingRequests(newRequests);
      if (newRequests.length === 0) {
        setIsOpenRequestList(false);
      }
    },
    [speakingRequests],
  );

  // highlight-start
  // Accepting means updating user permissions
  // and letting other participants know a new speaker is present by including the user id in speakerIds array
  const acceptRequest = useCallback(
    async (speakingRequest: PermissionRequestEvent) => {
      if (!(call && metadata?.custom)) return;

      await call?.updateUserPermissions({
        user_id: speakingRequest.user.id,
        grant_permissions: [...speakingRequest.permissions],
      });

      await call?.update({
        custom: {
          ...(metadata?.custom || {}),
          speakerIds: [
            ...(metadata?.custom.speakerIds || []),
            speakingRequest.user.id,
          ],
        },
      });

      dismissSpeakingRequest(speakingRequest);
    },
    [dismissSpeakingRequest, call, metadata?.custom],
  );
  // highlight-end

  // highlight-start
  // Register event handler to process arriving permission requests
  useEffect(() => {
    if (!(call && canUpdatePermissions)) return;
    const unsubscribe = call.on(
      'call.permission_request',
      (event: StreamCallEvent) => {
        if (event.type !== 'call.permission_request') return;

        setSpeakingRequests((prevSpeakingRequests) => [
          ...prevSpeakingRequests,
          event,
        ]);
        setIsOpenRequestList(true);
      },
    );

    return () => {
      unsubscribe();
    };
  }, [call, canUpdatePermissions]);
  // highlight-end

  return {
    acceptRequest,
    dismissSpeakingRequest,
    isOpenRequestList,
    setIsOpenRequestList,
    speakingRequests,
  };
};


```



3. The requester is notified the permission has been granted via `call.permissions_updated` WS event. An already mentioned  registered event handler in `LiveRoomControls` component will start to publish user's audio:
```ts
import {
  OwnCapability,
  StreamCallEvent,
} from '@stream-io/video-react-sdk';
import { useEffect } from 'react';
// omitted imports ...

// omitted code ...

export const LiveRoomControls = ({
  hasNotifications,
  openRequestsList,
}: LiveRoomControlsProps) => {
  // omitted code ...

  // highlight-start
  useEffect(() => {
    if (!(call && connectedUser)) return;
    return call.on('call.permissions_updated', (event: StreamCallEvent) => {
      if (event.type !== 'call.permissions_updated') return;
      if (connectedUser.id !== event.user.id) return;
      if (event.own_capabilities.includes(OwnCapability.SEND_AUDIO)) {
        setInitialAudioEnabled(true);
        publishAudioStream();
      } else {
        stopPublishingAudio();
      }
    });
  }, [
    call,
    connectedUser,
    publishAudioStream,
    setInitialAudioEnabled,
    stopPublishingAudio,
  ]);
  // highlight-end

  // omitted code ...
}
```

4. Now the participant with permission to speak can toggle audio mute state. The button has to account for the situation of a speaker leaving and re-joining the room. In that case the permission to speak has to be requested again.

```tsx
import {
  OwnCapability,
  SfuModels,
  useCall,
  useHasPermissions,
  useLocalParticipant,
  useMediaDevices,
} from '@stream-io/video-react-sdk';
import { useCallback } from 'react';
import {
  MicrophoneIcon,
  MuteMicrophoneIcon,
} from './icons';

type AudioRequestApprovalProps = {
  setIsAwaitingAudioApproval: (isAwaiting: boolean) => void;
};

const ToggleMuteButton = ({
  setIsAwaitingAudioApproval,
}: AudioRequestApprovalProps) => {
  const call = useCall();
  const localParticipant = useLocalParticipant();
  const canSendAudio = useHasPermissions(OwnCapability.SEND_AUDIO);

  const { publishAudioStream, stopPublishingAudio, setInitialAudioEnabled } =
    useMediaDevices();

  const isAudioMute = !localParticipant?.publishedTracks.includes(
    SfuModels.TrackType.AUDIO,
  );

  // highlight-start
  const toggleAudio = useCallback(async () => {
    if (!call) return;

    if (isAudioMute) {
      if (!canSendAudio) {
        setIsAwaitingAudioApproval(true);
        await call
          .requestPermissions({
            permissions: [OwnCapability.SEND_AUDIO],
          })
          .catch((reason) => {
            console.log('RequestPermissions failed', reason);
          });
        return;
      }

      setInitialAudioEnabled(true);
      await publishAudioStream();
    } else {
      stopPublishingAudio();
    }
  }, [
    call,
    canSendAudio,
    isAudioMute,
    publishAudioStream,
    setInitialAudioEnabled,
    setIsAwaitingAudioApproval,
    stopPublishingAudio,
  ]);
  // highlight-end

  return (
    <button
      className="icon-button"
      onClick={toggleAudio}
      title={isAudioMute ? 'Unmute' : 'Mute'}
    >
      {isAudioMute ? <MuteMicrophoneIcon /> : <MicrophoneIcon />}
    </button>
  );
};
```

### Putting the room components together

With updating permissions the user's ID is added to the `speakerIds` array in call's `custom` property, a new `SpeakerElement` is rendered. The `SpeakerElement` internally renders SDK's `Audio` component.

```tsx
import {
  Audio,
  // omitted imports...
  SfuModels,
  StreamVideoLocalParticipant,
  StreamVideoParticipant,
  useCall,
  // omitted imports...
} from '@stream-io/video-react-sdk';
// omitted imports...

export const SpeakerElement = ({
  speaker,
}: {
  speaker: StreamVideoParticipant | StreamVideoLocalParticipant;
}) => {
  const call = useCall();
  // omitted code ...
  if (!call) return null;

  const isAudioEnabled = speaker.publishedTracks.includes(
    SfuModels.TrackType.AUDIO,
  );

  return (
    <div className="speaker-container">
      // highlight-next-line
      <Audio muted={!isAudioEnabled} audioStream={speaker.audioStream} />
      {/* the rest of the UI */}
    </div>
  );
};
```

The speakers are filtered from room participants by id listed in `Call.custom.speakerIds` array. This is demonstrated in the `RoomUI` component below. This component also registers event handlers to reload the `Call` instance. That way we make sure the `Call` state is reset and ready for rejoining the room. The `RoomUI` component renders all the UI components mentioned and some more.

```tsx
import {
  CallingState,
  OwnCapability,
  Restricted,
  SfuEvents,
  SfuModels,
  StreamVideoEvent,
  StreamVideoLocalParticipant,
  StreamVideoParticipant,
  useCall,
  useCallCallingState,
  useCallMetadata,
  useHasPermissions,
  useIsCallLive,
  useLocalParticipant,
  useParticipants,
} from '@stream-io/video-react-sdk';
import { useEffect, useMemo } from 'react';
// some imports are omitted
import { useSpeakingRequests } from '../hooks/useSpeakingRequests';
// some imports are omitted
import type { CustomCallData } from '../types';

type RoomUIProps = {
  loadRoom: () => Promise<void>;
};

export const RoomUI = ({ loadRoom }: RoomUIProps) => {
  const call = useCall();
  const callMetadata = useCallMetadata();
  const isLive = useIsCallLive();
  const callingState = useCallCallingState();
  const localParticipant = useLocalParticipant();
  const participants = useParticipants();
  const canJoinBackstage = useHasPermissions(OwnCapability.JOIN_BACKSTAGE);
  const {
    acceptRequest,
    isOpenRequestList,
    dismissSpeakingRequest,
    setIsOpenRequestList,
    speakingRequests,
  } = useSpeakingRequests();
  const {
    title,
    hosts = [],
    speakerIds = [],
  } = (callMetadata?.custom || {}) as CustomCallData;

  // highlight-start
  useEffect(() => {
    if (!call || !localParticipant) return;

    // reload the Call data in order to reset the Call state when kicked out of the room due to stopping the live room
    const unsubscribeFromLiveEnded = call.on(
      'error',
      (e: SfuEvents.SfuEvent) => {
        if (e.eventPayload.oneofKind !== 'error') return;
        const { error } = e.eventPayload.error;
        if (!error || error.code !== SfuModels.ErrorCode.LIVE_ENDED) return;

        const hasPermissionToJoinBackstage =
          call.permissionsContext.hasPermission(OwnCapability.JOIN_BACKSTAGE);
        if (!hasPermissionToJoinBackstage) {
          loadRoom().catch((err) => {
            console.error(`Error loading room.`, err);
          });
        }
      },
    );

    // reload the Call data after leaving the room to be able to re-join it
    const unsubscribeFromParticipantLeft = call.on(
      'call.session_participant_left',
      (e: StreamVideoEvent) => {
        if (e.type !== 'call.session_participant_left') return;
        if (e.user_session_id === localParticipant.sessionId) {
          loadRoom().catch((err) => {
            console.error(`Error loading room.`, err);
          });
        }
      },
    );
    return () => {
      unsubscribeFromLiveEnded();
      unsubscribeFromParticipantLeft();
    };
  }, [loadRoom, call, localParticipant]);
  // highlight-end

  // filter the speakers
  const { speakers, listeners } = useMemo(() => {
    const hostIds = hosts.map((host) => host.id) || [];
    return participants.reduce<
      Record<string, (StreamVideoParticipant | StreamVideoLocalParticipant)[]>
    >(
      (acc, p) => {
        if (hostIds?.includes(p.userId) || speakerIds.includes(p.userId)) {
          acc.speakers.push(p);
        } else {
          acc.listeners.push(p);
        }
        return acc;
      },
      { speakers: [], listeners: [] },
    );
  }, [hosts, speakerIds, participants]);

  if (!call) return null;

  const showLobby =
    (!canJoinBackstage || (canJoinBackstage && isLive)) &&
    !callMetadata?.ended_at &&
    ![CallingState.JOINED].includes(callingState);

  const showRoomEnded = !!callMetadata?.ended_at && !showLobby;

  return (
   // ...please see the omitted elements rendered in the project's source code ...
  );
};

```


### Summary

In this guide, we've built a great example of how to fully customize the UI of our application by only accessing
the low-level hooks and functions of the call engine.

This is just an example of how to utilize the SDK to tailor it toward your specific use-case. In this tutorial, we have highlighted the most important parts of the workflow implemented by the Audio Rooms app. If you are interested in further implementation details, please, take a look at [the Audio rooms tutorial source code](https://github.com/GetStream/stream-video-js/tree/main/sample-apps/react/audio-rooms-tutorial).

For more examples check out our [Video Call Tutorial](../video-calling) as well as our [Livestream Tutorial](../livestream).

Let us know the cool things you have built with our SDK. We are always happy to learn about them.
