---
title: Video Call Tutorial
description: How to build a video call application similar to Zoom or Google Meet
---

import { TokenSnippet } from '../../../shared/_tokenSnippet.jsx';

This tutorial teaches you how to build Zoom/Whatsapp style video calling for your app.

- Calls run on Stream's global edge network for optimal latency & reliability.
- Permissions give you fine-grained control over who can do what.
- Video quality and codecs are automatically optimized.
- Powered by Stream's [Video Calling API](https://getstream.io/video/).

### Step 1 - Setup a new React Native app

Create a new React Native app using the official template,

```bash title=Terminal
npx react-native@latest init VideoCallExample
cd VideoCallExample
```

### Step 2 - Install the SDK and declare permissions

To install the Stream Video React Native SDK, run the following command in your terminal of choice:

```bash title=Terminal
yarn add @stream-io/video-react-native-sdk
```

The SDK requires installing some peer dependencies. You can run the following command to install them:

```bash title=Terminal
yarn add @stream-io/react-native-webrtc react-native-device-info \
   react-native-incall-manager react-native-svg \
   @react-native-community/netinfo @notifee/react-native
npx pod-install
```

#### Add Stream Video SDK's setup method

##### Android

Add the following in your `MainApplication.java` file:

<!-- vale off -->
```java
// highlight-next-line
import com.streamvideo.reactnative.StreamVideoReactNative;

public class MainApplication extends Application implements ReactApplication {

  @Override
  public void onCreate() {
    super.onCreate();
    // highlight-next-line
    StreamVideoReactNative.setup();
    // the rest..
  }
}
```
<!-- vale on -->

##### iOS

Add the following in your `AppDelegate.m` or `AppDelegate.mm` file:

```c
// highlight-next-line
#import "StreamVideoReactNative.h"

@implementation AppDelegate

- (BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions
{
  // highlight-next-line
  [StreamVideoReactNative setup];

  // the rest..
}
```

#### Declare permissions

##### iOS

Add the following keys and values to `Info.plist` file:

- `Privacy - Camera Usage Description` - "`VideoCallExample` requires camera access to capture and transmit video"
- `Privacy - Microphone Usage Description` - "`VideoCallExample` requires microphone access to capture and transmit audio"

##### Android

In `AndroidManifest.xml` add the following permissions before the `<application>` section.

```xml
<uses-feature android:name="android.hardware.camera" />
<uses-feature android:name="android.hardware.camera.autofocus" />
<uses-feature android:name="android.hardware.audio.output" />
<uses-feature android:name="android.hardware.microphone" />

<uses-permission android:name="android.permission.CAMERA" />
<uses-permission android:name="android.permission.RECORD_AUDIO" />
<uses-permission android:name="android.permission.ACCESS_NETWORK_STATE" />
<uses-permission android:name="android.permission.CHANGE_NETWORK_STATE" />
<uses-permission android:name="android.permission.MODIFY_AUDIO_SETTINGS" />
<uses-permission android:name="android.permission.INTERNET" />
```

If you plan to also support Bluetooth devices then also add the following.

```xml
<uses-permission android:name="android.permission.BLUETOOTH" android:maxSdkVersion="30" />
<uses-permission android:name="android.permission.BLUETOOTH_ADMIN" android:maxSdkVersion="30" />
<uses-permission android:name="android.permission.BLUETOOTH_CONNECT" />
```

:::note
For simplicity, in this tutorial, we do not cover about managing native runtime permissions. Before starting the next step, ensure that camera and microphone permissions are given for this app by granting them in the native settings app. We have discussed a detailed solution to manage native runtime permissions in the [Manage Native Permissions](../../core/native-permissions) guide.
:::

#### Android Specific installation

In `android/app/build.gradle` add the following inside the `android` section:

```java
compileOptions {
	sourceCompatibility JavaVersion.VERSION_1_8
	targetCompatibility JavaVersion.VERSION_11
}
```

In `android/gradle.properties` add the following:

```groovy
android.enableDexingArtifactTransform.desugaring=false
```

### Step 3 - Create & Join a call

Open up `src/App.tsx` and replace it with this code:

```tsx title="App.tsx"
import {
  StreamVideoClient,
  Call,
  CallingState,
  StreamVideo,
  StreamCall,
  User,
  useCall,
  useCallCallingState,
  useParticipantCount,
  StreamVideoRN,
} from '@stream-io/video-react-native-sdk';
import React, { useState, useEffect } from 'react';
import { SafeAreaView, Text } from 'react-native';

// for simplicity, we assume that permission was granted through the native settings app
StreamVideoRN.setPermissions({
  isMicPermissionGranted: true,
  isCameraPermissionGranted: true,
});

const apiKey = 'REPLACE_WITH_API_KEY'; // the API key can be found in the "Credentials" section
const token = 'REPLACE_WITH_TOKEN'; // the token can be found in the "Credentials" section
const userId = 'REPLACE_WITH_USER_ID'; // the user id can be found in the "Credentials" section
const callId = 'REPLACE_WITH_CALL_ID'; // the call id can be found in the "Credentials" section

// set up the user object
const user: User = {
  id: userId,
  name: 'Santhosh',
  image: `https://getstream.io/random_png/?id=${userId}&name=Santhosh`,
};

const client = new StreamVideoClient({ apiKey, user, token });

export default function App() {
  const [call, setCall] = useState<Call>();
  useEffect(() => {
    const myCall = client.call('default', callId);
    myCall.join({ create: true }).catch((err) => {
      console.error('Failed to join the call', err);
    });

    setCall(myCall);

    return () => {
      setCall(undefined);
      myCall.leave().catch((err) => {
        console.error('Failed to leave the call', err);
      });
    };
  }, []);

  if (!call) {
    return null;
  }

  return (
    <StreamVideo client={client}>
      <StreamCall call={call}>
        <SafeAreaView style={{ flex: 1 }}>
          <VideoCallUI />
        </SafeAreaView>
      </StreamCall>
    </StreamVideo>
  );
}

const VideoCallUI = () => {
  const call = useCall();
  const callingState = useCallCallingState();
  const participantCount = useParticipantCount();

  if (callingState !== CallingState.JOINED) {
    return <Text style={{ fontSize: 30, color: 'black' }}>Loading...</Text>;
  }

  return (
    <Text style={{ fontSize: 30, color: 'black' }}>
      Call "{call?.id}" has {participantCount} participants
    </Text>
  );
};
```

Let's review what we did in the above code.

#### User setup

First we create a user object. You typically sync these users via a server side integration from your own backend. Alternatively, you can also use guest or anonymous users.

```ts
import type { User } from '@stream-io/video-react-native-sdk';

const user: User = {
  id: userId,
  name: 'Santhosh',
  image: `https://getstream.io/random_png/?id=${userId}&name=Santhosh`,
};
```

#### Client setup

Next we initialize the client by passing the API Key, user and user token.

```ts
import { StreamVideoClient } from '@stream-io/video-react-native-sdk';

const client = new StreamVideoClient({ apiKey, user, token });
```

#### Create and join call

After the user and client are created, we create a call like this:

```ts
const [call, setCall] = useState<Call>();
useEffect(() => {
  const myCall = client.call('default', callId);
  myCall.join({ create: true }).catch((err) => {
    console.error(`Failed to join the call`, err);
  });

  setCall(myCall);

  return () => {
    setCall(undefined);
    myCall.leave().catch((err) => {
      console.error(`Failed to leave the call`, err);
    });
  };
}, []);
```

As soon as you use `call.join()` the connection for video & audio is setup.

Lastly, the UI is rendered by observing the call state through the state hooks (participants and connection states):

```tsx
import {
  useCallCallingState,
  useParticipantCount,
} from '@stream-io/video-react-native-sdk';

const callingState = useCallCallingState();
const participantCount = useParticipantCount();
```

You'll find all relevant state for the call in `call.state` also exposed through a set of SDK provided hooks.
The documentation on [Call and Participant state](../../core/call-and-participant-state/) explains this in further detail.

#### Credentials

For testing, please update **REPLACE_WITH_API_KEY**, **REPLACE_WITH_TOKEN**, **REPLACE_WITH_USER_ID** and **REPLACE_WITH_CALL_ID** with the actual values shown below::

<TokenSnippet sampleApp="meeting" displayStyle="credentials" />

Now when you run the sample app it will connect successfully. The text will say "Call ... has 1 participant" (yourself) like below:

![Preview of the initial run](../assets/02-tutorials/01-video-calling/video-call-preview.png)

### Step 4 - Joining from the web

To make this a little more interactive, let's join the call from your browser.

<TokenSnippet sampleApp="meeting" displayStyle="join" />

In your app, you'll see the text update to 2 participants. Let's keep the browser tab open as you go through the tutorial.

### Step 5 - Rendering Video

In this step, we are going to add the participant's view which displays the participants' video and audio stream and other related info. We also add a call controls that allows the user to control their streaming settings of audio and video.

To do this we use `CallContent` and `CallControls` components.

The `CallContent` adds the following things to the UI automatically:

- Indicators of when someone is speaking.
- Quality of their network.
- Layout support for multiple participants.
- Labels for the participant names, media stream on/off status.
- A floating local video view.

The `CallControls` adds the toggle audio/video button, switch camera button and the hang up call button automatically.

Update the `VideoCallUI` component as below:

```tsx title="src/App.tsx"
// ... omitted imports
import { CallContent, CallControls } from '@stream-io/video-react-native-sdk';

// ... omitted code

const VideoCallUI = () => {
  return (
    <>
      // highlight-next-line
      <CallContent />
      // highlight-next-line
      <CallControls />
    </>
  );
};
```

Now when you run the app, you'll see your local video in a floating video element and the video from your other browser tab. You should also see the buttons to control the streaming settings. The end result should look like this:

![Preview of the video view](../assets/02-tutorials/01-video-calling/video-call.png)

### Step 6 - Full Video Calling UI

Next, we will add the `ParticipantsInfoBadge`, to make our UI complete. It is responsible to handle the following:

- Show the number of participants in the form of a badge.
- Show the information about the participants in a list with the name, and status of media streaming.
- Show available options within the call like pinning a participant, enabling/disabling audio/video, etc.

Update the `VideoCallUI` component as below:

```tsx title="src/App.tsx"
// ... omitted imports
import { View, StyleSheet } from 'react-native';
import {
  CallContent,
  CallControls,
  ParticipantsInfoBadge,
} from '@stream-io/video-react-native-sdk';

// ... omitted code

const VideoCallUI = () => {
  return (
    <>
      // highlight-start
      <View style={styles.icons}>
        <ParticipantsInfoBadge />
      </View>
      // highlight-end
      <CallContent />
      <CallControls />
    </>
  );
};

const styles = StyleSheet.create({
  icons: {
    position: 'absolute',
    right: 16,
    marginTop: 16,
    flexDirection: 'row',
    alignItems: 'center',
    zIndex: 2,
  },
});
```

Now when you run the app and tap the icon on the top right you should see the list of participants in the call. The end result should look like this:

![Preview of the list of participants](../assets/02-tutorials/01-video-calling/video-call-participants-info.png)

### Step 7 - Customizing the UI

You can customize the UI by:

- Building your own UI components (the most flexibility, build anything).
- Mixing and matching with Stream's UI Components (speeds up how quickly you can build custom video UI).

You can find many examples on how to build your own custom UI components in our [UI Cookbook docs](../../ui-cookbook/overview/).

### Recap

Please do let us know if you ran into any issues while building an video calling app with React Native. Our team is also happy to review your UI designs and offer recommendations on how to achieve it with Stream.

To recap what we've learned about Stream video calling:

- You set up a call: (`const call = client.call("default", "your-call-id")`)
- The call type ("default" in the above case) controls which features are enabled and how permissions are setup
- When you join a call, real-time communication is set up for audio & video calling: (`call.join()`)
- State-related hooks such as `useCallCallingState` make it easy to build your own UI
- `CallContent` is the component that renders audio and video
- `CallControls`is the component that renders buttons to control streaming options
- `ParticipantsInfoBadge` is the component that can be used to show the list of participants

We've used [Stream's Video Calling API](https://getstream.io/video/), which means calls run on a global edge network of video servers. By being closer to your users the latency and reliability of calls are better. The React Native SDK enables you to build in-app video calling, audio rooms and livestreaming in days.

We hope you've enjoyed this tutorial and please do feel free to reach out if you have any suggestions or questions.
