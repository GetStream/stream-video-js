---
id: 01-tutorial
title: Tutorial
---

## Introduction

Hi there and welcome to our Stream Video React Native tutorial.

`StreamVideo` is an SDK that facilitates adding calling (audio and video) support to your apps. It's a performant and highly customizable, allowing you to build various types of calling applications and streaming use cases, such as:

- **Messenger-style applications**: These applications implement Chat as a primary source of communication, with Video secondary.
- **Meeting-style applications**: Such apps focus primarily on Video, with Chat as a way to communicate while in a call. Eg: Zoom, Google Meet, etc.
- **Audio Rooms**: Our SDK allows you to build audio-only rooms that allow live communication, such as Twitter Spaces.
- **Livestreaming**: We support one of the most popular modern use cases - streaming audio and video to audiences. You can replicate apps like Twitch or YouTube Live.

This makes the Stream Video SDK the best-in-class choice when integrating Audio and Video communication in your apps. With all that in mind, let's dive into the tutorial.

## Tutorial Contents

:::info
In the following tutorial we will focus on building a Meeting-style application, such as Zoom, Google Meet, etc.

If your app resembles a Ring-style application, such as Messenger, then please, follow the guide [Chat With Video](../../guides/06-chat-with-video/).
:::

We will explain how to integrate Stream Video to support Meetings in your Application.

In this tutorial, we are building a video call application using the Stream Video React SDK. We will be implementing a "Meeting Room" scenario, where users can join and leave the call independently, without causing the call to be terminated. The topics we are covering in this tutorial are:

- Setting up the project.
- Creating the call UI/screens using built-in components.
- Creating/Joining a new call.
- Leaving an existing call.
- View Participants info.

To get started with the guide, ensure you have set up your [development environment for React Native](https://reactnative.dev/docs/environment-setup). Stream Chat supports creating applications using Expo and React Native CLI. But Stream Video currently only supports React Native CLI, so we will only focus on React Native CLI in this documentation.

## Create a new project

Create a new RN project with TypeScript

```bash
npx react-native init StreamMeetingTutorial --template react-native-template-typescript
```

## Install dependencies and initial setup

Follow this [guide](01-basics/03-installation.mdx) to install the dependencies and setup the project.

## Planning the Screens

The app is supposed to have 2 screens, one for creating a meeting with a meeting id through a text input, and the other for handling the meeting.
We use [react-navigation](http://reactnavigation.org/) to set up the navigator. To do this, we will firstly define the types.

```tsx title="src/types.ts"
export type NavigationStackParamsList = {
  JoinMeetingScreen: undefined;
  MeetingScreen: { callId: string; callType: string };
};
```

Finally, set up the stack navigator and the stack screen.

```tsx title="App.tsx"
import React from 'react';
import { NavigationStackParamsList } from './src/types';
import { createNativeStackNavigator } from '@react-navigation/native-stack';
import { NavigationContainer } from '@react-navigation/native';
import { JoinMeetingScreen } from './src/screens/JoinMeetingScreen';
import { MeetingScreen } from './src/screens/MeetingScreen';

const Stack = createNativeStackNavigator<NavigationStackParamsList>();

const UltimateRoot = () => {
  return (
    <Stack.Navigator>
      <Stack.Screen name="JoinMeetingScreen" component={JoinMeetingScreen} />
      <Stack.Screen
        name="MeetingScreen"
        component={MeetingScreen}
        options={{ headerShown: false }}
      />
    </Stack.Navigator>
  );
};

function App(): JSX.Element {
  return (
    <NavigationContainer>
      {/* Providing our app's global state*/}
      {/*Root of our app*/}
      <UltimateRoot />
    </NavigationContainer>
  );
}

export default App;
```

### Creating Join Meeting screen

This screen is required to have a text input where the id of the meeting to be joined can be entered and a button to create/start the call.
We can use the create call button to show/navigate to LobbyView component/screen.
Our implementation of this screen is as follows:

```tsx title="src/screens/JoinMeetingScreen.tsx"
import React, { useCallback, useState } from 'react';
import { Button, SafeAreaView, Text, TextInput, View } from 'react-native';
import { NativeStackScreenProps } from '@react-navigation/native-stack';
import { NavigationStackParamsList } from '../types';

type JoinMeetingScreenProps = NativeStackScreenProps<
  NavigationStackParamsList,
  'JoinMeetingScreen'
>;

export const JoinMeetingScreen = (props: JoinMeetingScreenProps) => {
  const [callId, setCallId] = useState<string>('');
  const { navigation } = props;

  const joinCallHandler = useCallback(() => {
    navigation.navigate('MeetingScreen', {
      callId: callId,
      callType: 'default',
    });
  }, [navigation]);

  return (
    <SafeAreaView>
      <View>
        <Text>{'Whats the call ID?'}</Text>
      </View>
      <TextInput
        value={callId}
        onChangeText={(text) => setCallId(text.trim().split(' ').join('-'))}
      />
      <Button
        title={'Create meeting with callID: ' + callId}
        color="blue"
        disabled={!callId}
        onPress={joinCallHandler}
      />
    </SafeAreaView>
  );
};
```

## Creating Meeting a Permissions Management Hook

In this step we will create a hook to manage the permissions required for the app to function properly.
This hook will be used to sync the permissions of the app with the Stream Video SDK.
We will ask for relevant permissions after the parent screen is mounted and when app state changes to foreground.
This ensures the latest permissions are synced with the Stream Video SDK, that way the SDK will subscribe to
audio/video devices as preparation for a call.

```tsx title="src/hooks/useSyncPermissions.tsx"
import { useEffect } from 'react';
import { Platform } from 'react-native';
// We will be using react-native-permissions lib. to manage our permissions
import {
  checkMultiple,
  PERMISSIONS,
  PermissionStatus,
  requestMultiple,
  RESULTS
} from 'react-native-permissions';

import { StreamVideoRN } from '@stream-io/video-react-native-sdk';

export const useSyncPermissions = () => {
  useEffect(() => {
    // Check, update and sync permissions after parent component mounts
    checkAndUpdatePermissions();
  }, []);
  // useAppStateListener(handleOnForeground, () => {});
};

const checkAndUpdatePermissions = async () => {
  if (Platform.OS === 'ios') {
    // Request camera and mic permissions on iOS
    const results = await requestMultiple([
      PERMISSIONS.IOS.CAMERA,
      PERMISSIONS.IOS.MICROPHONE,
    ]);
    // Sync the permissions with the Stream Video SDK
    // This ensures that the SDK will subscribe to audio/video devices as preparation for a call.
    iOSProcessResultsAndSetToConfig(results);
    return;
  } else if (Platform.OS === 'android') {
    // Request camera, mic, bluetooth and notification permissions on Android
    const results = await requestMultiple([
      PERMISSIONS.ANDROID.CAMERA,
      PERMISSIONS.ANDROID.RECORD_AUDIO,
      PERMISSIONS.ANDROID.BLUETOOTH_CONNECT,
      PERMISSIONS.ANDROID.POST_NOTIFICATIONS,
    ]);
    // Sync the camera and permissions with the Stream Video SDK
    // This ensures that the SDK will subscribe to audio/video devices as preparation for a call.
    androidProcessResultsAndSetToConfig(results);
  }
};

const androidProcessResultsAndSetToConfig = (
  results: Record<
    'android.permission.CAMERA' | 'android.permission.RECORD_AUDIO',
    PermissionStatus
  >,
) =>
  // Sync the permissions with the Stream Video SDK
  // by setting the permissions to the config.
  StreamVideoRN.setPermissions({
    isCameraPermissionGranted:
      results[PERMISSIONS.ANDROID.CAMERA] === RESULTS.GRANTED,
    isMicPermissionGranted:
      results[PERMISSIONS.ANDROID.RECORD_AUDIO] === RESULTS.GRANTED,
  });

const iOSProcessResultsAndSetToConfig = (
  results: Record<
    'ios.permission.CAMERA' | 'ios.permission.MICROPHONE',
    PermissionStatus
  >,
) =>
  // Sync the permissions with the Stream Video SDK
  // by setting the permissions to the config.
  StreamVideoRN.setPermissions({
    isCameraPermissionGranted:
      results[PERMISSIONS.IOS.CAMERA] === RESULTS.GRANTED,
    isMicPermissionGranted:
      results[PERMISSIONS.IOS.MICROPHONE] === RESULTS.GRANTED,
  });

```
In order to sync the permissions when the app comes back to foreground, we will add a listener to the app state change event.
This will ensure that the permissions are always in sync when the user comes back to the app from background after
changing the permissions in the app's settings screen.

```tsx title="src/hooks/useSyncPermissions.tsx"
import {useEffect, useRef} from 'react';
import {AppState, AppStateStatus, Platform} from 'react-native';

// We will be using react-native-permissions lib. to manage our permissions
import {checkMultiple, PERMISSIONS} from 'react-native-permissions';

export const useSyncPermissions = () => {
  // Check, update and sync permissions...
  useEffect(() => {
    // ...after parent component mounts
    checkAndUpdatePermissions();
  }, []);
  // ...after user comes back to the app from background to foreground.
  // This is important because the user might have changed the permissions in the app's
  // settings screen while the app was in background.
  const appStateRef = useRef(AppState.currentState);
  useEffect(() => {
    const handleAppStateChange = async (nextAppState: AppStateStatus) => {
      const prevAppState = appStateRef.current;
      if (
        prevAppState.match(/inactive|background/) &&
        nextAppState === 'active'
      ) {
        await handleOnForeground();
      }
    };
    const subscription = AppState.addEventListener(
      'change',
      handleAppStateChange,
    );

    return () => {
      AppState.removeEventListener('change', handleAppStateChange);
    };
  }, []);
};

const handleOnForeground = async () => {
  if (Platform.OS === 'ios') {
    // Check, update and sync permissions on iOS
    const results = await checkMultiple([
      PERMISSIONS.IOS.CAMERA,
      PERMISSIONS.IOS.MICROPHONE,
    ]);
    // Sync the permissions with the Stream Video SDK
    iOSProcessResultsAndSetToConfig(results);
  } else if (Platform.OS === 'android') {
    // Check, update and sync permissions on Android
    const results = await checkMultiple([
      PERMISSIONS.ANDROID.CAMERA,
      PERMISSIONS.ANDROID.RECORD_AUDIO,
    ]);
    // Sync the permissions with the Stream Video SDK
    androidProcessResultsAndSetToConfig(results);
  }
};

const checkAndUpdatePermissions = async () => {...};
const androidProcessResultsAndSetToConfig = (results) => {...};
const iOSProcessResultsAndSetToConfig = (results) => {...};
```

### Creating and providing the Video Client

We will start by creating a simple video meeting with Stream's Video SDK.

#### Create a video client

To create a client, we can use `StreamVideoClient` class that will be used to communicate to Stream's Video backend and create a new client.
This expects an API key as the first argument, the user object with id, name, image and other details as the second argument and user token as the second.
The `StreamVideoClient` is internally responsible to create a client, connect with the user and cleanup when the component is unmounted.

```tsx title="src/screens/MeetingScreen.tsx"
import React, { useState, useEffect } from 'react';
import { StreamVideoClient } from '@stream-io/video-react-native-sdk';

export const MeetingScreen = () => {
  const [videoClient, setVideoClient] = useState<StreamVideoClient | undefined>(
    undefined,
  );
  const user = {
    id: 'micheal',
    name: 'Micheal',
    imageUrl: 'https://randomuser.me/api/portraits/men/44.jpg',
  };
  const USER_TOKEN = 'YOUR_TOKEN';
  const API_KEY = 'YOUR_API_KEY';

  useEffect(() => {
    const _videoClient = new StreamVideoClient({
      apiKey: STREAM_API_KEY,
      user,
      tokenProvider,
    });
    setVideoClient(_videoClient);

    return () => {
      _videoClient.disconnectUser();
      setVideoClient(undefined);
    };
  }, [tokenProvider, user]);

  ...
};
```

#### Provide the video client logic to the rest of the app

Our `StreamVideo` component will provide our recently created video client to the rest of the underlying components.
The `client` created above can be used as follows and needs to be provided to the `client` prop of the `StreamVideo` component.

```tsx title="src/screens/MeetingScreen.tsx"
import React, { useState, useEffect } from 'react';
import { ActivityIndicator, StyleSheet } from 'react-native';
import {
  StreamVideo,
  StreamVideoClient,
} from '@stream-io/video-react-native-sdk';

const MeetingScreen = () => {
  const [videoClient, setVideoClient] = useState<StreamVideoClient | undefined>(
    undefined,
  );
  const user = {
    id: 'micheal',
    name: 'Micheal',
    imageUrl: 'https://randomuser.me/api/portraits/men/44.jpg',
  };
  const USER_TOKEN = 'YOUR_TOKEN';
  const API_KEY = 'YOUR_API_KEY';

  useEffect(() => {
    const _videoClient = new StreamVideoClient({
      apiKey: STREAM_API_KEY,
      user,
      tokenProvider,
    });
    setVideoClient(_videoClient);

    return () => {
      _videoClient.disconnectUser();
      setVideoClient(undefined);
    };
  }, [tokenProvider, user]);

  if (!videoClient) {
    return <ActivityIndicator size={'large'} style={StyleSheet.absoluteFill} />;
  }

  return <StreamVideo client={videoClient}>{children}</StreamVideo>;
};
```

### Providing and creating call

Our `StreamCall` component internally serves the purpose of creating the call for the given call id and call type. We can use it and wrap it to the screen/component where the call should be available.

```tsx title="src/screens/MeetingScreen.tsx"
import React from 'react';
import { StreamVideo, StreamCall } from '@stream-io/video-react-native-sdk';
import { NativeStackScreenProps } from '@react-navigation/native-stack';
import { NavigationStackParamsList } from '../types';

type Props = NativeStackScreenProps<NavigationStackParamsList, 'MeetingScreen'>;

const MeetingScreen = (props: Props) => {
  ...
  const { route } = props;
  const {
    params: { callId, callType },
  } = route;

  return (
    <StreamVideo client={videoClient}>
      <StreamCall callId={callId} callType={callType}>
        {children}
      </StreamCall>
    </StreamVideo>
  );
};
```

### Adding call cycle handlers

`StreamCall` component has also a `callCycleHandlers` prop of type object that expects `onCallJoined`, `onCallHungUp` and `onCallJoining` handlers (among other handlers) to deal with transitions between the call states.
These handlers can be used to perform preparation/teardown tasks or navigation between screens.

An example can be seen below:

```tsx title="src/screens/MeetingScreen.tsx"
import { StreamVideo, StreamCall } from '@stream-io/video-react-native-sdk';
import { NativeStackScreenProps } from '@react-navigation/native-stack';
import { NavigationStackParamsList } from '../types';

type Props = NativeStackScreenProps<NavigationStackParamsList, 'MeetingScreen'>;

const MeetingScreen = (props: Props) => {
  const [show, setShow] = useState<
    'lobby' | 'loading' | 'active-call'
  >('lobby');

  ...
  const { navigation, route } = props;
  const {
    callParams: { callId, callType },
  } = route;
  ...

  const onJoin = () => {
    setShow('active-call');
  };

  const onLeave = () => {
    setShow('lobby');
    navigation.goBack();
  };

  const onJoining = () => {
    setShow('loading');
  };

  return (
    <StreamVideo client={videoClient}>
      <StreamCall
        callId={callId}
        callType={callType}
        callCycleHandlers={{
          onCallJoined: onJoin,
          onCallJoining: onJoining,
          onCallHungUp: onLeave,
        }}
      >
        {children}
      </StreamCall>
    </StreamVideo>
  );
};
```

### Rendering the LobbyView and ActiveCall components

To render the call lobby component and active call components, you can import `LobbyView` and `ActiveCall` component from the Video SDK and use it
in the Screen/View.

```tsx title="src/screens/MeetingScreen.tsx"
import React from 'react';
import { SafeAreaView, ActivityIndicator } from 'react-native';
import {
  LobbyView,
  ActiveCall,
} from '@stream-io/video-react-native-sdk';

export const MeetingScreen = () => {
  const [show, setShow] = useState<'lobby' | 'loading' | 'active-call'>(
    'lobby',
  );
  ...
  let ComponentToRender: JSX.Element | null = null;

  if (show === 'lobby') {
    ComponentToRender = <LobbyView />;
  } else if (show === 'loading') {
    ComponentToRender = (
      <SafeAreaView style={styles.container}>
        <ActivityIndicator size={'large'} style={StyleSheet.absoluteFill} />
      </SafeAreaView>
    );
  } else {
    ComponentToRender = <ActiveCall />;
  }

  return (
    <StreamVideo client={videoClient}>
      <StreamCall
        callId={callId}
        callType={callType}
        callCycleHandlers={{
          onCallJoined: onJoin,
          onCallJoining: onJoining,
          onCallHungUp: onLeave,
        }}
      >
        {ComponentToRender}
      </StreamCall>
    </StreamVideo>
  );
};

const styles = StyleSheet.create({
  container: {
    flex: 1,
  },
});
```

## Further Integration

Congratulations on completing this tutorial. You've learned how to build two very popular use cases - Meeting and Ringing Calls. However, our SDK supports multiple other use cases and more advanced features. If you're looking to integrate more of our supported functionality, we recommend checking out the following guides:

[//]: # '* [guide](05-advanced/02-push-notification/01-overview.mdx)'

(../02-guides/05-socket-events.mdx)

- [Call Lifecycle](../02-guides/02-call-lifecycle.mdx): It's important to understand the lifecycle of our SDK and Calls to properly build complex use cases for your users.
- [Call Engine](../02-guides/03-call-engine.mdx): If you're looking to utilize our state machine to the fullest, explore what our internal CallEngine does and how to listen to state.
- [Deep linking](../05-advanced/01-deeplinking.mdx): Deep linking is very useful for Meeting apps where you can simply send a link for the Call that lets people join.
- [Push Notifications](../05-advanced/02-push-notifications.mdx): Apps where Ring people and invite them to Calls heavily rely on push notifications. Learn how to integrate them with our SDK.

Alternatively, if you're modeling your app based on popular apps, like Messenger, Telegram, Zoom, Google Meet, Twitter Spaces or Twitch, we have several guides and template projects prepared for you:

- [Chat + Video](../02-guides/06-chat-with-video.mdx): Messenger and Telegram like applications feature Chat as a primary source of communication, with Video being secondary. To build a similar app, follow our Chat + Video guide that provides you with a template project to kick start your app, with all the UI and setup pre-baked.
- [Audio Rooms](../02-guides/07-audio-rooms.mdx): Some apps feature live audio rooms where people gather to discuss ideas and fun topics. Apps like Twitter Spaces are popular and you can build them using our Audio Rooms guide. It also prepares a template project for you that cuts the time you need to start working on your app.
- [Livestream](../02-guides/08-livestream.mdx): Last, but not least, our Livestream guide teaches you how to build an app where one person streams their tracks to a group of people in real time. By the end of the guide, you'll have a project that prepares most of the setup for you.
