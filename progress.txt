# Picture in Picture iOS Improvements Progress

## Iteration 1 - US-001: Auto-start PiP on background (when enabled)
- **Task Status:** Already implemented
- **Verification:** All tests pass, TypeScript check passes
- **Implementation Details:**
  - `StreamPictureInPictureController.swift:69,83` - Sets `canStartPictureInPictureAutomaticallyFromInline = true` by default
  - `StreamPictureInPictureController.swift:186-189` - Applies this setting to `AVPictureInPictureController`
  - `CallContent.tsx:240-244` - Conditionally renders `RTCViewPipIOS` based on `disablePictureInPicture` prop
  - `RTCViewPipIOS.tsx:119-122` - Handles PiP state changes and updates `isInPiPMode$` RxJS subject
  - `useIsInPiPMode.tsx` - React hook that subscribes to `isInPiPMode$` subject

- **Learnings for future iterations:**
  - The current implementation already aligns with upstream `stream-video-swift` PR #258 architecture
  - PiP controller uses `AVPictureInPictureVideoCallViewController` (iOS 15+) with sample buffer rendering
  - RxJS subjects (`isInPiPMode$`, `disablePiPMode$`) manage PiP state across JS components
  - The native PiP controller lifecycle is tied to the `RTCViewPip` UIView superview attachment/detachment
  - `shouldDisableIOSLocalVideoOnBackgroundRef` controls whether local video should be disabled when backgrounding
---

## Iteration 13 - PiP empty-track regression fixes
- **Task Status:** Implemented
- **Verification:** Manual validation (PiP enter twice)

### Implementation Summary:
Fixed the black PiP window when a track exists but renders no frames, including the regression on the second PiP entry. Also removed the redundant JS `isVideoEnabled` prop and derived video-enabled state from `streamURL` on the native side.

### Files Modified:

**Native iOS (Swift/ObjC):**
1. **StreamPictureInPictureVideoRenderer.swift**
   - Track render state (`hasRenderedFrame`) now resets on window attach/detach.
   - Avatar visibility is driven by actual frame rendering, preventing black frames.

2. **RTCViewPip.swift**
   - Removed public `isVideoEnabled` prop.
   - Derived `isVideoEnabled` from `streamURL`/track availability.

3. **RTCViewPipManager.mm**
   - Removed `isVideoEnabled` export from the bridge.

**TypeScript/React:**
4. **RTCViewPipIOS.tsx**
   - Removed `hasVideo` usage and `isVideoEnabled` prop forwarding.

5. **RTCViewPipNative.tsx**
   - Removed `isVideoEnabled` prop from native component contract.

### Key Design Decisions:
- Use “has rendered at least one frame” as the gate for video display.
- Fall back to avatar until the first valid frame arrives, even if a track exists.
- Avoid duplicated video-enabled logic in JS; compute from `streamURL` in native.
---

## Iteration 2 - US-002: PiP renders the correct participant and doesn't go "blank"
- **Task Status:** Already implemented
- **Verification:** All tests pass, TypeScript check passes
- **Implementation Details:**
  - `RTCViewPipIOS.tsx:36-52` - Participant selection logic:
    - Uses `speakerLayoutSortPreset` to sort by speaker activity
    - Filters based on `includeLocalParticipantVideo` prop
    - Prefers remote participant when local is dominant and remote exists
  - `RTCViewPipIOS.tsx:102-110` - Screen share handling:
    - Checks `hasScreenShare(participant)` to determine if screen sharing
    - Renders `screenShareStream` when active, otherwise `videoStream`
  - `StreamPictureInPictureVideoRenderer.swift:12-20` - Track change handling:
    - `prepareForTrackRendering()` properly stops old stream and starts new
    - Ensures smooth transition without blank frames

- **Learnings for future iterations:**
  - Track changes are handled reactively through the `streamURL` prop
  - `DimensionsUpdatedRenderless` component tracks video dimensions and updates native side
  - The debouncing (300ms) on participants helps avoid unnecessary rerenders during rapid track subscriptions
---

## Iteration 3 - US-003: PiP window sizing is stable and configurable
- **Task Status:** Fixed and implemented
- **Verification:** All tests pass, build succeeds
- **Issue Found:** The `preferredContentSize` was not being set by default, which could cause iOS `PGPegasus code:-1003` error
- **Changes Made:**
  - `StreamPictureInPictureController.swift:81-83` - Added default `preferredContentSize` of 640x480 on init
  - `StreamPictureInPictureController.swift:89-95` - Added guard in `setPreferredContentSize()` to prevent setting `.zero`
- **Existing Implementation Details (already correct):**
  - `RTCViewPipIOS.tsx:97` - JS validates `width > 0 && height > 0` before sending dimensions
  - `StreamPictureInPictureAdaptiveWindowSizePolicy.swift:13` - Guards against `.zero` trackSize
  - `StreamPictureInPictureVideoRenderer.swift:211` - Guards against `.zero` in `didUpdateTrackSize()`
  - `StreamPictureInPictureVideoRenderer.swift:226` - Updates window size policy when track size changes

- **Learnings for future iterations:**
  - iOS requires `preferredContentSize` > `.zero` or it throws `PGPegasus code:-1003`
  - Always set a default size on initialization (640x480 is a safe default)
  - Multi-layer guards prevent invalid sizes from propagating
---

## Iteration 4 - US-004: PiP stops and cleans up on call end / leave
- **Task Status:** Fixed and implemented
- **Verification:** All tests pass, build succeeds
- **Issues Found and Fixed:**
  1. **Combine subscriptions not cancelled:** `cancellableBag` was not cleared on cleanup
  2. **Track state adapter timer not stopped:** `trackStateAdapter.isEnabled` was not set to false
  3. **Controller not recreated for subsequent calls:** After cleanup, `pictureInPictureController` was nil but never recreated

- **Changes Made:**
  - `StreamPictureInPictureController.swift:170-185` - Enhanced `cleanup()` method:
    - Added `cancellableBag.removeAll()` to cancel Combine subscriptions
    - Added `trackStateAdapter.isEnabled` to false to stop the timer
    - Added `trackStateAdapter.activeTrack = nil` to release track reference
  - `RTCViewPip.swift:91-95` - Added controller recreation logic:
    - When view is added to superview and controller is nil, recreate it
    - This enables PiP to work again for subsequent calls

- **Existing Implementation Details (already correct):**
  - `RTCViewPipIOS.tsx:61-93` - Listens for `call.ended` and `CallingState.LEFT`
  - `RTCViewPip.swift:67-71` - Native `onCallClosed()` calls cleanup
  - `StreamPictureInPictureController.swift` - cleanup() releases all resources

- **Learnings for future iterations:**
  - Always cancel Combine subscriptions in cleanup
  - Timer-based adapters need explicit disabling
  - Controllers may need to be recreated after cleanup for view reuse scenarios
---

## Iteration 5 - US-005: PiP UI controls and overlays match upstream Swift library
- **Task Status:** NOT IMPLEMENTED - Requires significant new development
- **Analysis Completed:** Researched upstream implementation and technical requirements

### Upstream Implementation Analysis:
The `stream-video-swift` library's PiP implementation includes these overlays:
1. **ParticipantInfoView** - Displays participant name and mute indicator at bottom
2. **ConnectionQualityIndicator** - Shows connection quality (top right)
3. **Speaking indicator** - Border highlight when participant is speaking

The upstream uses a SwiftUI-based approach with `UIHostingController` wrapping `PictureInPictureContentView`.
The React Native SDK uses a simpler UIKit approach with direct `AVSampleBufferDisplayLayer` rendering.

### Technical Requirements to Implement:
1. **New Native Views:**
   - `PiPParticipantOverlayView` - UIView containing name label and mute indicator
   - `PiPConnectionQualityView` - UIView for connection quality icon
   - Speaking indicator border (CALayer)

2. **New Bridge Props (internal, not public API):**
   - `participantName: String` - Name to display
   - `isMuted: Bool` - Audio mute status
   - `isSpeaking: Bool` - Speaking indicator
   - `connectionQuality: String` - Connection quality level

3. **Changes Required:**
   - `RTCViewPipManager.mm` - Add new RCT_EXPORT_VIEW_PROPERTY entries
   - `RTCViewPip.swift` - Add new props and forward to controller
   - `StreamPictureInPictureController.swift` - Accept participant state
   - `StreamAVPictureInPictureVideoCallViewController.swift` - Add overlay views
   - `RTCViewPipNative.tsx` - Accept new props
   - `RTCViewPipIOS.tsx` - Pass participant state to native

4. **Estimated Effort:** Multi-day implementation including:
   - Native Swift view development
   - Bridge modifications
   - Layout management
   - Testing across iOS versions

### Why Not Implemented This Iteration:
- Requires substantial new code across multiple layers
- No existing mechanism to pass participant metadata to native
- Would need careful design to avoid breaking existing API
- Time-intensive testing for PiP overlays across iOS 15-18

### Recommendation for Future Iterations:
- Create a detailed design document for the overlay system
- Consider using a single JSON prop to pass participant state
- Test overlay rendering performance in PiP window
- Ensure overlays scale correctly for different PiP sizes
---

## Iteration 6 - US-011: PiP controller and adapter infrastructure
- **Task Status:** Implemented
- **Verification:** TypeScript tests pass, iOS build succeeds

### Files Created:
1. **PictureInPictureDelegateProxy.swift** - Wraps `AVPictureInPictureControllerDelegate` with Combine publisher
   - Publishes events: willStart, didStart, failedToStart, willStop, didStop, restoreUI
   - Enables reactive handling of PiP lifecycle events

2. **StreamPictureInPictureControllerProtocol.swift** - Interface contract for PiP controller
   - Defines `isPictureInPictureActivePublisher` and `stopPictureInPicture()`
   - Extends `AVPictureInPictureController` to conform

3. **PictureInPictureEnforcedStopAdapter.swift** - Enforces PiP stop on foreground
   - Listens to `UIApplication.didBecomeActiveNotification`
   - Uses timer to ensure PiP stops when app returns to foreground

### Files Modified:
- **StreamPictureInPictureController.swift**:
  - Replaced direct `AVPictureInPictureControllerDelegate` conformance with `PictureInPictureDelegateProxy`
  - Added `enforcedStopAdapter` for foreground transition handling
  - Improved event handling through reactive Combine subscriptions
  - Added proper cleanup of `enforcedStopAdapter`

### Adaptation Notes:
The upstream `stream-video-swift` uses:
- `@Injected` dependency injection system
- `PictureInPictureStore` centralized state management
- SwiftUI with `UIHostingController` for content views
- `DisposableBag` custom cancellable management
- `DefaultTimer` custom timer abstraction

The React Native SDK adaptation:
- Uses direct property injection and callbacks (no DI system)
- Keeps existing UIKit-based approach (no SwiftUI)
- Uses standard Combine `Set<AnyCancellable>` pattern
- Uses standard `Timer.publish()` from Combine

### Learnings for future iterations:
- Upstream SwiftUI files (ViewFactory, SourceView, ContentProvider) need UIKit adaptation
- Delegate proxy pattern enables cleaner event handling via Combine
- Enforced stop adapter improves user experience when returning to app
- Protocol-based design allows for easier testing and flexibility
---

## Iteration 7 - US-005: Participant avatar placeholder when video is disabled
- **Task Status:** Implemented
- **Verification:** JS build succeeds, iOS dogfood build succeeds

### Implementation Summary:
Implemented a complete avatar placeholder system that shows participant profile image, initials, or a default icon when video is disabled in PiP mode.

### Files Created/Modified:

**Native iOS (Swift):**
1. **PictureInPictureAvatarView.swift** (already existed, verified working)
   - UIView that displays avatar with three fallback levels:
     1. Profile image from URL (async loaded)
     2. Initials generated from participant name
     3. SF Symbol person icon as default
   - Circular avatar centered in dark background
   - Responsive sizing (40% of container, minimum 60pt)

2. **StreamPictureInPictureVideoRenderer.swift** - Added avatar integration
   - `participantName`, `participantImageURL`, `isVideoEnabled` properties
   - Avatar view added to view hierarchy, shows/hides based on `isVideoEnabled`

3. **StreamAVPictureInPictureVideoCallViewController.swift** - Added protocol conformance
   - Implements `participantName`, `participantImageURL`, `isVideoEnabled` properties
   - Forwards values to contentView (renderer)

4. **StreamPictureInPictureController.swift** - Added bridge properties
   - `@objc public var participantName`, `participantImageURL`, `isVideoEnabled`
   - Forwards values to contentViewController

5. **RTCViewPip.swift** - Added React Native bridge properties
   - `@objc public var participantName: NSString?`
   - `@objc public var participantImageURL: NSString?`
   - `@objc public var isVideoEnabled: Bool`
   - Forwards values to pictureInPictureController

6. **RTCViewPipManager.mm** - Added property exports
   - `RCT_EXPORT_VIEW_PROPERTY(participantName, NSString)`
   - `RCT_EXPORT_VIEW_PROPERTY(participantImageURL, NSString)`
   - `RCT_EXPORT_VIEW_PROPERTY(isVideoEnabled, BOOL)`

**TypeScript/React:**
7. **RTCViewPipNative.tsx** - Added TypeScript types
   - Extended props with `participantName`, `participantImageURL`, `isVideoEnabled`
   - Updated forwarded props in NativeComponent

8. **RTCViewPipIOS.tsx** - Added participant info passing
   - `isVideoEnabled` computed from participant state and track availability
   - Uses `hasVideo()` utility from video-client to check publishing state
   - Passes `participantName`, `participantImageURL`, `isVideoEnabled` to native

### Key Design Decisions:
- Used UIKit-based approach (not SwiftUI) to match existing SDK architecture
- Three-level avatar fallback: image → initials → default icon
- Async image loading with URLSession and proper cleanup
- Video enabled state derived from both stream availability and publishing state

### Learnings for future iterations:
- React Native bridge properties work well for passing participant state
- `hasVideo()` utility is the correct way to check if participant has video enabled
- Avatar view visibility controlled by `isHidden` property on the view
- Profile image URL comes from `participant.image` property
- Always clean up URLSession tasks when new URL is set
---

## Iteration 8 - US-006: Reconnection view during connection recovery
- **Task Status:** Verified complete (already implemented)
- **Verification:** JS build succeeds, iOS dogfood build succeeds

### Implementation Summary:
The reconnection view feature was already fully implemented across the entire stack. This iteration verified the implementation works correctly.

### Files Involved:

**Native iOS (Swift):**
1. **PictureInPictureReconnectionView.swift** - UIKit view with reconnection indicator
   - Dark semi-transparent background (0.12, 0.13, 0.15, alpha: 0.85)
   - UIActivityIndicatorView spinner (large, white)
   - "Reconnecting..." message label
   - `isReconnecting` property controls visibility
   - Starts/stops activity indicator animation based on state

2. **StreamPictureInPictureVideoRenderer.swift:54-57, 129-130, 202, 215-218, 223-230**
   - Contains `reconnectionView` property
   - `isReconnecting` property forwards to reconnection view
   - Priority system: reconnection view > avatar view > video content
   - Reconnection view added to view hierarchy with full-frame constraints

3. **StreamAVPictureInPictureVideoCallViewController.swift:38-39, 77-79**
   - `isReconnecting` property in protocol and implementation
   - Forwards to contentView (renderer)

4. **StreamPictureInPictureController.swift:70-73**
   - `@objc public var isReconnecting: Bool`
   - Forwards to contentViewController

5. **RTCViewPip.swift:44-47**
   - `@objc public var isReconnecting: Bool`
   - Forwards to pictureInPictureController

6. **RTCViewPipManager.mm:18**
   - `RCT_EXPORT_VIEW_PROPERTY(isReconnecting, BOOL)`

**TypeScript/React:**
7. **RTCViewPipNative.tsx:26-27, 70, 90**
   - `isReconnecting?: boolean` prop type
   - Forwarded to NativeComponent

8. **RTCViewPipIOS.tsx:141-144, 155**
   - Connection state detection:
     ```tsx
     const isReconnecting =
       callingState === CallingState.RECONNECTING ||
       callingState === CallingState.RECONNECTING_FAILED;
     ```
   - Passed to RTCViewPipNative component

### Key Design Decisions:
- Uses `CallingState.RECONNECTING` and `CallingState.RECONNECTING_FAILED` from video-client
- UIKit-based approach consistent with avatar placeholder implementation
- Priority system ensures reconnection view appears above other content
- Smooth transitions via isHidden property toggling

### Learnings for future iterations:
- CallingState enum includes RECONNECTING and RECONNECTING_FAILED states
- The `useCallCallingState()` hook provides real-time connection state
- Layer hierarchy with priority system (reconnection > avatar > video) works well
- Activity indicator automatically starts/stops when visibility changes
---

## Iteration 9 - US-007: Screen sharing view in PiP
- **Task Status:** Implemented
- **Verification:** JS build succeeds, iOS dogfood build succeeds

### Implementation Summary:
Implemented screen sharing indicator view that displays when screen sharing content is being shown in PiP mode. The existing implementation already handled screen share rendering and aspect ratio correctly - this iteration added the visual indicator.

### Files Created:

**Native iOS (Swift):**
1. **PictureInPictureScreenShareIndicatorView.swift** - UIKit view showing screen share indicator
   - Displays "Screen" label with rectangle-on-rectangle SF Symbol icon
   - Positioned in top-left corner with semi-transparent dark background
   - Visibility controlled by `isScreenSharing` property
   - Uses rounded container with horizontal stack layout

### Files Modified:

**Native iOS (Swift):**
2. **StreamPictureInPictureVideoRenderer.swift**
   - Added `isScreenSharing` property
   - Added `screenShareIndicatorView` lazy property
   - Added screen share indicator view to view hierarchy in `setUp()`
   - Indicator positioned in top-left corner over video content

3. **StreamAVPictureInPictureVideoCallViewController.swift**
   - Added `isScreenSharing` property to protocol `StreamAVPictureInPictureViewControlling`
   - Added `isScreenSharing` computed property forwarding to contentView

4. **StreamPictureInPictureController.swift**
   - Added `@objc public var isScreenSharing: Bool` property
   - Forwards to contentViewController

5. **RTCViewPip.swift**
   - Added `@objc public var isScreenSharing: Bool` property
   - Forwards to pictureInPictureController

6. **RTCViewPipManager.mm**
   - Added `RCT_EXPORT_VIEW_PROPERTY(isScreenSharing, BOOL)`

**TypeScript/React:**
7. **RTCViewPipNative.tsx**
   - Added `isScreenSharing?: boolean` to props types
   - Added forwarding of `isScreenSharing` prop to NativeComponent

8. **RTCViewPipIOS.tsx**
   - Added `isScreenSharing` prop to RTCViewPipNative component
   - Existing `isScreenSharing` variable (line 106-108) already computed from `hasScreenShare()`

### Key Design Decisions:
- Minimal visual indicator (small icon + "Screen" label) to not obstruct content
- Positioned in top-left corner to avoid interference with video controls
- Uses SF Symbol `rectangle.on.rectangle` for universal recognition
- Semi-transparent dark background for contrast on any content
- UIKit-based approach consistent with other overlay views

### Existing Functionality Verified:
- Screen share content already renders correctly (handled by `screenShareStream`)
- Aspect ratio handling via `pictureInPictureWindowSizePolicy` works for screen share
- Transitions between screen share and camera video smooth (track change in renderer)
- Both local and remote participant screen share supported

### Learnings for future iterations:
- Screen share detection already existed via `hasScreenShare()` from video-client
- The upstream `stream-video-swift` uses a separate view type but functionally equivalent
- SF Symbols (iOS 13+) provide good icons without bundling assets
- Indicator overlay doesn't need special z-ordering - just add last to subviews
---

## Iteration 10 - US-008: PiP content view system and state management
- **Task Status:** Implemented
- **Verification:** iOS dogfood build succeeds

### Implementation Summary:
Integrated the upstream content view architecture for centralized PiP state management. The system provides a unified way to manage content switching between video, avatar, reconnection, and screen share views.

### Files Created:

**Native iOS (Swift):**
1. **PictureInPictureContent.swift** - Data model representing PiP content states
   - Enum with cases: inactive, video, avatar, screenSharing, reconnecting
   - Associated values for track, participant name, and image URL
   - Equatable conformance for state comparison
   - Convenience properties: `track`, `participantName`, `hasActiveVideo`, etc.

2. **PictureInPictureContentState.swift** - Centralized state manager
   - Adapted from upstream `PictureInPictureStore`
   - Uses Combine for reactive state updates via `contentPublisher`
   - Thread-safe with serial DispatchQueue
   - Raw state properties: track, participantName, participantImageURL, isVideoEnabled, isScreenSharing, isReconnecting
   - Automatic content type determination based on priority
   - `reset()` method for cleanup

### Files Modified:

3. **StreamPictureInPictureController.swift**
   - Added `contentState` property for centralized state management
   - All state properties now update both contentState and contentViewController
   - Added `currentContent` computed property for debugging
   - Added `setupContentStateSubscriptions()` for logging state changes
   - Enhanced cleanup to reset content state

4. **StreamAVPictureInPictureVideoCallViewController.swift**
   - Extended protocol with `contentState` and `content` properties
   - Implementation forwards to contentView (renderer)

5. **StreamPictureInPictureVideoRenderer.swift** (previously modified in US-005/US-006/US-007)
   - Already supports both legacy individual properties and unified content enum
   - Supports subscription to PictureInPictureContentState for reactive updates
   - `applyContent()` method synchronizes enum state with individual properties

### Key Design Decisions:
- Dual update path: Both contentState AND direct contentViewController updates for backward compatibility
- Content priority: reconnecting > avatar (video disabled) > screen sharing > video > inactive
- Thread-safe state transitions using serial DispatchQueue
- Combine publisher for reactive UI updates

### Learnings for future iterations:
- The content state system allows for future enhancements like batched updates
- Logging content state changes helps with debugging PiP issues
- Maintaining backward compatibility through dual update paths is crucial
- The `reset()` method is important for cleanup when calls end
---

## Iteration 11 - US-009: Participant information overlay
- **Task Status:** Implemented
- **Verification:** iOS dogfood build succeeds

### Implementation Summary:
Implemented participant name and mute status overlay that displays at the bottom of the PiP window. The overlay shows when video is enabled and hides during reconnection or when showing avatar placeholder.

### Files Created:

**Native iOS (Swift):**
1. **PictureInPictureParticipantOverlayView.swift** - UIKit view for participant info overlay
   - Gradient background at bottom for readability
   - Participant name label (truncated if needed)
   - Mute icon (mic.slash.fill SF Symbol) when audio is muted
   - Visibility controlled by `isOverlayEnabled` based on PiP state
   - Positioned at bottom, non-obtrusive to video content

### Files Modified:

**Native iOS (Swift):**
2. **StreamPictureInPictureVideoRenderer.swift**
   - Added `isMuted` property for mute state
   - Added `isParticipantOverlayEnabled` property
   - Added `participantOverlayView` lazy property
   - Updated `setUp()` to add overlay to view hierarchy
   - Updated `participantName` setter to also forward to overlay
   - Updated `updateOverlayVisibility()` to control overlay visibility
     - Overlay hidden during reconnection
     - Overlay hidden when showing avatar (video disabled)
     - Overlay shown only when video is active

3. **StreamAVPictureInPictureVideoCallViewController.swift**
   - Added `isMuted` property to protocol `StreamAVPictureInPictureViewControlling`
   - Added `isMuted` computed property forwarding to contentView

4. **StreamPictureInPictureController.swift**
   - Added `@objc public var isMuted: Bool` property
   - Forwards to contentViewController

5. **RTCViewPip.swift**
   - Added `@objc public var isMuted: Bool` property
   - Forwards to pictureInPictureController

6. **RTCViewPipManager.mm**
   - Added `RCT_EXPORT_VIEW_PROPERTY(isMuted, BOOL)`

**TypeScript/React:**
7. **RTCViewPipNative.tsx**
   - Added `isMuted?: boolean` to props types
   - Added forwarding of `isMuted` prop to NativeComponent

8. **RTCViewPipIOS.tsx**
   - Added `hasAudio` import from video-client
   - Added `isMuted` computed value using `!hasAudio(participantInSpotlight)`
   - Passed `isMuted` prop to RTCViewPipNative

### Key Design Decisions:
- Gradient background (transparent to semi-transparent black) ensures text readability on any video content
- Small, non-obtrusive overlay positioned at bottom (28pt height)
- Mute icon only shown when participant is muted
- Overlay automatically hidden when:
  - Showing reconnection view (user knows connection is unstable)
  - Showing avatar placeholder (name already in avatar context)
- Uses `hasAudio()` utility from video-client for accurate mute detection

### Learnings for future iterations:
- CAGradientLayer needs frame update in `layoutSubviews()` with animation disabled
- The `hasAudio()` function checks if participant is publishing audio track
- Overlay visibility should follow the same priority as other overlays (reconnection > avatar > video)
- SF Symbols provide consistent iconography across iOS versions (13+)
---

## Iteration 12 - US-010: Video rendering pipeline improvements
- **Task Status:** Verified complete (already implemented)
- **Verification:** iOS dogfood build succeeds

### Implementation Summary:
The video rendering pipeline files were already fully implemented and aligned with the upstream `stream-video-swift` implementation. This iteration verified that all required components exist and function correctly.

### Files Verified:

**Video Rendering Core:**
1. **StreamPictureInPictureVideoRenderer.swift** (495 lines)
   - Main renderer implementing RTCVideoRenderer protocol
   - Frame skipping optimization based on size ratios (threshold: 15x)
   - Resize logic triggered when frame > content size
   - Supports multiple content overlays (avatar, reconnection, screen share, participant info)
   - Unified content system via PictureInPictureContent enum
   - Reactive updates via PictureInPictureContentState subscription

2. **SampleBufferVideoCallView.swift** (53 lines)
   - UIView with AVSampleBufferDisplayLayer as layer class
   - iOS 17+ support via AVSampleBufferVideoRenderer
   - SampleBufferVideoRendering protocol abstraction

**Buffer Transformation:**
3. **StreamBufferTransformer.swift** (96 lines)
   - Transforms RTCVideoFrame buffers with optional resizing
   - Aspect ratio preserving resize via `resizeSize(_:toFitWithin:)`
   - Always uses I420 buffer (proven more reliable than RTCCVPixelBuffer)

**YUV Conversion:**
4. **StreamRTCYUVBuffer.swift** (250 lines)
   - YUV to ARGB conversion using Accelerate framework
   - Implements RTCVideoFrameBuffer protocol
   - Lazy i420ToYUVPixelBuffer initialization
   - Support for both I420 and CVPixelBuffer sources
   - CMSampleBuffer creation with DisplayImmediately attachment

5. **StreamYUVToARGBConversion.swift** (128 lines)
   - Configurable YUV to ARGB conversion
   - Supports ITU-R BT.601 and BT.709 color matrices
   - Uses vImageConvert_YpCbCrToARGB_GenerateConversion

6. **YpCbCrPixelRange+Default.swift** (33 lines)
   - Default pixel range configuration for video
   - Full range: Yp 1-255, CbCr 0-255

**Pixel Buffer Management:**
7. **StreamPixelBufferPool.swift** (118 lines)
   - CVPixelBufferPool wrapper for memory efficiency
   - Configurable max buffer count (default: 5)
   - Error handling for allocation threshold exceeded

8. **StreamPixelBufferRepository.swift** (99 lines)
   - Multi-pool management for different sizes/formats
   - Thread-safe access via UnfairQueue (os_unfair_lock)
   - Automatic pool creation on demand

### Key Architecture:
```
RTCVideoFrame → StreamBufferTransformer → StreamRTCYUVBuffer → CMSampleBuffer → SampleBufferVideoCallView
                     ↓ resize                    ↓ YUV→ARGB
               StreamPixelBufferRepository   StreamYUVToARGBConversion
```

### Performance Optimizations:
- Frame skipping: Skip frames when source >> display size (ratio > 15x)
- Resize threshold: Resize when ratio >= 1x to prevent oversized frames
- Pixel buffer pooling: Reuse CVPixelBuffer instances to reduce allocations
- Hardware acceleration: vImage framework for YUV conversion
- Lazy initialization: i420ToYUVPixelBuffer only created when needed

### Learnings for future iterations:
- All rendering pipeline components were previously ported and verified working
- The upstream naming differs slightly: `PictureInPictureVideoRenderer` → `StreamPictureInPictureVideoRenderer`
- The RN SDK uses UIKit-based approach while upstream uses SwiftUI with UIHostingController
- Frame skipping threshold of 15x and resize threshold of 1x provide good balance
- UnfairQueue with os_unfair_lock provides fastest synchronization for pixel buffer access
---

## Iteration 14 - Upstream Alignment Review
- **Task Status:** Implemented
- **Verification:** Pending iOS build

### Analysis Summary:
Reviewed the current implementation against upstream `stream-video-swift` to identify unnecessary additions and align behavior.

### Upstream Analysis:
Fetched and analyzed files from https://github.com/GetStream/stream-video-swift/tree/develop/Sources/StreamVideoSwiftUI/Utils/PictureInPicture:
- `PictureInPictureVideoRenderer.swift` - No `hasRenderedFrame` tracking, simpler overlay logic
- `PictureInPictureContent.swift` - States: inactive, participant, screenSharing, reconnecting
- `PictureInPictureStore.swift` - Centralized state management
- `PictureInPictureParticipantModifier.swift` - Shows name, connection quality, speaking indicator (NOT mute icon)
- `PictureInPictureScreenSharingView.swift` - Just video with participant modifier overlay (NO separate indicator)

### Unnecessary Additions Identified and Removed:

1. **`PictureInPictureScreenShareIndicatorView.swift`** - REMOVED
   - Upstream does NOT have a separate "Screen" label indicator
   - Upstream just applies participant name overlay to screen share content
   - Files modified: Deleted file, removed references from renderer

2. **Mute indicator in `PictureInPictureParticipantOverlayView`** - REMOVED
   - Upstream shows: participant name, connection quality, speaking indicator
   - Upstream does NOT have a mute icon
   - PRD states: "No new PiP UI controls beyond upstream"
   - Files modified: `PictureInPictureParticipantOverlayView.swift`, removed `isMuted` prop chain

3. **`hasRenderedFrame` tracking** - REMOVED
   - Upstream does NOT track whether frames have been rendered
   - Content switching in upstream is based on: track != nil AND isVideoEnabled
   - Our implementation added `hasRenderedFrame` to fix black PiP window issue, but this deviates from upstream
   - Files modified: `StreamPictureInPictureVideoRenderer.swift`

4. **`updateOverlayVisibility()` simplification** - ALIGNED WITH UPSTREAM
   - Upstream: Avatar shows when track is nil OR isVideoEnabled is false
   - Our implementation: Previously also checked `hasRenderedFrame`
   - Now aligned: `let shouldShowVideo = isVideoEnabled && track != nil`

### Files Modified:

**Deleted:**
- `PictureInPictureScreenShareIndicatorView.swift`

**Native iOS (Swift):**
- `StreamPictureInPictureVideoRenderer.swift`:
  - Removed `hasRenderedFrame` property and all references
  - Simplified `updateOverlayVisibility()` to match upstream logic
  - Removed hasRenderedFrame checks from `renderFrame()`, `willMove(toWindow:)`, `startFrameStreaming()`, `stopFrameStreaming()`, `getCurrentContent()`

- `StreamAVPictureInPictureVideoCallViewController.swift`:
  - Removed `isMuted` property from protocol and implementation

- `StreamPictureInPictureController.swift`:
  - Removed `isMuted` property

- `RTCViewPip.swift`:
  - Removed `isMuted` property

- `RTCViewPipManager.mm`:
  - Removed `isMuted` export

- `PictureInPictureParticipantOverlayView.swift`:
  - Removed `isMuted` property
  - Removed mute icon view
  - Simplified layout to just show participant name

**TypeScript/React:**
- `RTCViewPipNative.tsx`:
  - Removed `isMuted` prop from types and component

- `RTCViewPipIOS.tsx`:
  - Removed `hasAudio` import
  - Removed `isMuted` computation and prop

### Key Design Decisions:
- Aligned with upstream to minimize code drift and simplify future updates
- Removed enhancements that were not in upstream (mute icon, screen share indicator, hasRenderedFrame)
- Kept `isScreenSharing` property for content state tracking (used internally, no visual indicator)

### Trade-offs:
- Removing `hasRenderedFrame` may reintroduce the "black PiP window" issue in edge cases where track exists but produces no frames
- However, this aligns with upstream behavior and the issue should be rare in practice since JS derives `isVideoEnabled` from streamURL availability

### Learnings:
- Upstream uses SwiftUI declaratively; content switching happens at view level based on store state
- Our UIKit approach requires explicit visibility management, but should follow same logic
- PRD clearly states "No new PiP UI controls beyond upstream" - important to follow this guideline
---

## Iteration 15 - Upstream Alignment: ParticipantInfoView Sound and Video Paused Indicators
- **Task Status:** Implemented
- **Verification:** Pending iOS build

### Analysis Summary:
Upon further investigation of upstream `ParticipantInfoView.swift`, discovered that upstream DOES show audio/video indicators - but different from what was initially implemented:
- **Sound indicator**: Microphone icon showing on/off state (NOT speaking border)
- **Video paused indicator**: wifi.slash icon when video track is paused

### Implementation Summary:
Re-implemented participant overlay to match upstream ParticipantInfoView behavior with sound indicator and video paused indicator.

### Files Modified:

**Native iOS (Swift):**
1. **PictureInPictureParticipantOverlayView.swift** - Complete rewrite
   - Added `hasAudio` property: When false, shows `mic.slash.fill` SF Symbol
   - Added `isTrackPaused` property: When true, shows `wifi.slash` SF Symbol
   - Horizontal layout: [name label] [spacer] [video paused icon] [audio icon]
   - Icons use SF Symbols with white color on semi-transparent dark background
   - Gradient overlay at bottom for text readability

2. **StreamPictureInPictureVideoRenderer.swift**
   - Added `hasAudio` property forwarding to overlay
   - Added `isTrackPaused` property forwarding to overlay

3. **StreamAVPictureInPictureVideoCallViewController.swift**
   - Added `hasAudio` and `isTrackPaused` to protocol
   - Added computed properties forwarding to contentView

4. **StreamPictureInPictureController.swift**
   - Added `@objc public var hasAudio: Bool = true`
   - Added `@objc public var isTrackPaused: Bool = false`
   - Forwards to contentViewController

5. **RTCViewPip.swift**
   - Added `@objc public var hasAudio: Bool = true`
   - Added `@objc public var isTrackPaused: Bool = false`
   - Forwards to pictureInPictureController

6. **RTCViewPipManager.mm**
   - Added `RCT_EXPORT_VIEW_PROPERTY(hasAudio, BOOL)`
   - Added `RCT_EXPORT_VIEW_PROPERTY(isTrackPaused, BOOL)`

**TypeScript/React:**
7. **RTCViewPipNative.tsx**
   - Added `hasAudio?: boolean` to props types
   - Added `isTrackPaused?: boolean` to props types
   - Forwarded both props to NativeComponent

8. **RTCViewPipIOS.tsx**
   - Imported `hasAudio` and `hasPausedTrack` from `@stream-io/video-client`
   - Computed `participantHasAudio` using `hasAudio(participantInSpotlight)`
   - Computed `isVideoTrackPaused` using `hasPausedTrack(participantInSpotlight, trackType)`
   - Passed both values to RTCViewPipNative

### Key Design Decisions:
- `hasAudio`: Shows mic icon state (on when true, mic.slash when false)
- `isTrackPaused`: Shows wifi.slash icon when video track is paused (bandwidth saving mode)
- Icons positioned on right side of overlay, name on left
- Default values: `hasAudio = true`, `isTrackPaused = false` (normal video state)
- Uses existing `hasAudio()` and `hasPausedTrack()` utilities from video-client

### Difference from Previous Implementation:
- Previous: Had `isMuted` which was the inverse logic (true = no audio)
- Current: Uses `hasAudio` which is positive logic (true = audio enabled)
- Added: `isTrackPaused` for video paused state (wasn't in previous implementation)

### Learnings:
- Upstream ParticipantInfoView uses SoundIndicator component with hasAudio property
- Track paused state indicates bandwidth-saving mode, not user-initiated mute
- Both indicators are important for showing complete participant state in PiP
---

## Iteration 16 - Avatar View Layout Fix & Overlay Alignment with Upstream
- **Task Status:** Implemented
- **Verification:** Pending iOS build

### Root Cause Analysis:
The avatar view was not showing (black screen instead of blue circle with initials) due to:
1. **Using `isHidden` instead of `alpha` for visibility** - Upstream SwiftUI uses `opacity` for visibility switching. When using `isHidden = true`, iOS may skip calling `layoutSubviews` on hidden views, causing layout issues when the view becomes visible.
2. **Overlay visibility was incorrectly hidden when showing avatar** - Upstream shows participant info overlay (name, mic, connection quality, speaking border) on BOTH video AND avatar views.

### Key Upstream Analysis:
From `PictureInPictureVideoParticipantView.swift`:
```swift
var body: some View {
    PictureInPictureVideoRendererView(...)
        .opacity(showVideo ? 1 : 0)      // Video uses opacity, not isHidden
        .overlay(overlayView)             // Avatar overlay
        .pictureInPictureParticipant(...) // Participant info shown ALWAYS
}
```

The `.pictureInPictureParticipant()` modifier adds:
- ParticipantInfoView (name, pin icon, paused track indicator, sound indicator)
- ConnectionQualityIndicator
- Speaking border (via VideoCallParticipantSpeakingModifier)

These are shown on TOP of BOTH video and avatar - only hidden during reconnection.

### Files Modified:

**Native iOS (Swift):**
1. **PictureInPictureAvatarView.swift**
   - Changed `updateVisibility()` to use `alpha` instead of `isHidden`
   - Added `setNeedsLayout()` and `layoutIfNeeded()` when becoming visible
   - Updated comment to explain why alpha is used (matches upstream SwiftUI opacity)

2. **StreamPictureInPictureVideoRenderer.swift**
   - Changed avatar view initialization from `isHidden = true` to `alpha = 0`
   - Updated `updateOverlayVisibility()`:
     - Avatar now uses `alpha` instead of `isHidden` for visibility
     - Participant overlay now shows on BOTH video and avatar (was only showing on video)
     - Speaking border now shows on BOTH video and avatar (was only showing on video)
   - Updated `updateSpeakingIndicator()`:
     - Border shows when speaking, on both video and avatar
     - Only hidden during reconnection (matches upstream)

### Key Design Decisions:
1. **Use `alpha` instead of `isHidden`** - Ensures `layoutSubviews` is always called for proper Auto Layout constraint resolution. This matches upstream SwiftUI's opacity-based visibility.

2. **Participant overlay always visible (except during reconnection)** - Matches upstream behavior where ParticipantInfoView and ConnectionQualityIndicator appear on both video and avatar content.

3. **Speaking border always visible (except during reconnection)** - Matches upstream's VideoCallParticipantSpeakingModifier behavior.

### Upstream Alignment Summary:
| Feature | Before | After (Aligned with Upstream) |
|---------|--------|-------------------------------|
| Avatar visibility | `isHidden` | `alpha` (matches `opacity`) |
| Participant info overlay | Only on video | On video AND avatar |
| Connection quality indicator | Only on video | On video AND avatar |
| Speaking border | Only on video | On video AND avatar |
| All overlays during reconnection | Hidden | Hidden (no change) |

### Learnings:
- SwiftUI's `opacity` keeps views in the layout hierarchy; UIKit's `isHidden` may skip layout
- Always use `alpha` for visibility when Auto Layout constraints need to be resolved
- Force layout update with `setNeedsLayout()` + `layoutIfNeeded()` when showing previously invisible views
- Upstream shows all participant indicators regardless of video/avatar state
---

## Iteration 17 - Fix Avatar Not Showing on Subsequent PiP Sessions
- **Task Status:** Implemented
- **Verification:** Pending iOS build

### Problem:
Avatar was visible on the FIRST PiP entry but NOT on subsequent entries (second time and later).

### Root Cause:
When the `pictureInPictureController` is recreated after cleanup (for subsequent calls), the property values (participantName, isVideoEnabled, etc.) were NOT being re-applied to the new controller.

**Why this happens:**
1. First PiP session works - controller exists, React Native sets properties via didSet
2. Call ends - `onCallClosed()` sets `pictureInPictureController = nil`
3. Second PiP session - controller is recreated in `didMoveToSuperview()`
4. BUT: React Native properties (participantName, etc.) haven't changed
5. THEREFORE: `didSet` doesn't fire on RTCViewPip properties
6. RESULT: New controller has nil/default values, avatar doesn't show

### Solution:
Added `applyCurrentPropertiesToController()` method that explicitly re-applies all current property values to the newly created controller after recreation.

### Files Modified:

**RTCViewPip.swift:**
- Added `applyCurrentPropertiesToController()` private method
- Called this method after controller recreation in `didMoveToSuperview()`
- Re-applies: participantName, participantImageURL, isReconnecting, isScreenSharing, hasAudio, isTrackPaused, isPinned, isSpeaking, connectionQuality
- Special handling for streamURL to re-trigger track lookup and isVideoEnabled state

### Code Added:
```swift
private func applyCurrentPropertiesToController() {
    NSLog("PiP - Applying current properties to new controller")
    pictureInPictureController?.participantName = participantName as String?
    pictureInPictureController?.participantImageURL = participantImageURL as String?
    pictureInPictureController?.isReconnecting = isReconnecting
    pictureInPictureController?.isScreenSharing = isScreenSharing
    pictureInPictureController?.hasAudio = hasAudio
    pictureInPictureController?.isTrackPaused = isTrackPaused
    pictureInPictureController?.isPinned = isPinned
    pictureInPictureController?.isSpeaking = isSpeaking
    pictureInPictureController?.connectionQuality = connectionQuality

    // Re-apply streamURL to set track and isVideoEnabled
    if let streamURLString = streamURL as String? {
        let currentURL = streamURL
        streamURL = nil
        streamURL = currentURL
    } else {
        pictureInPictureController?.track = nil
        pictureInPictureController?.isVideoEnabled = false
    }
}
```

### Learnings:
- When recreating native objects, didSet on wrapper properties won't fire if values haven't changed
- Always explicitly re-apply state after object recreation
- This is a common pattern issue in React Native bridges where the native side may be recreated independently

### Update (same iteration):
Improved the fix by adding a `didSet` observer to `pictureInPictureController` itself:
- When controller transitions from nil → non-nil, automatically calls `applyCurrentPropertiesToController()`
- Added detailed logging to trace property flow
- Clarified that we read from RTCViewPip's own properties (which persist) and write to the new controller
---

## Iteration 18 - Debug Avatar Not Showing: Trace Property Chain
- **Task Status:** In Progress (Debugging)
- **Issue:** Avatar still shows black screen on second PiP entry despite overlays being visible

### Problem Analysis:
User logs showed:
- Avatar view has proper bounds (264x198)
- Avatar view has alpha=1.0 (visible)
- participantName="Santhosh Vaiyapuri" exists in renderer
- BUT: No `AvatarView.participantName didSet` or `updateInitials` logs appearing

This suggests the property chain is broken between the renderer and the avatar view.

### Property Chain (should flow):
1. RTCViewPip.participantName → (didSet) →
2. StreamPictureInPictureController.participantName → (didSet) →
3. StreamAVPictureInPictureVideoCallViewController.participantName → (setter) →
4. StreamPictureInPictureVideoRenderer.participantName → (didSet) →
5. PictureInPictureAvatarView.participantName → (didSet) → updateInitials()

### Debugging Logs Added:
1. **RTCViewPip.swift** - Already had logging: `"PiP - RTCViewPip.participantName didSet"`
2. **StreamPictureInPictureController.swift** - Added: `"PiP - Controller.participantName didSet: '...', contentViewController exists: ..."`
3. **StreamPictureInPictureVideoRenderer.swift** - Added: `"PiP - Renderer.participantName didSet: '...', forwarding to avatarView"`
4. **PictureInPictureAvatarView.swift** - Already had logging: `"PiP - AvatarView.participantName didSet: '...'"`

### Additional Logging Added:
- `Renderer.isVideoEnabled` didSet now logs `avatarView.participantName` state
- `updateOverlayVisibility()` now logs both `participantName` and `avatarView.participantName`
- `AvatarView.updateInitials()` now logs `avatarContainerView.frame`
- `applyCurrentPropertiesToController()` now logs "STARTING" and "COMPLETED"

### Expected Log Output on Second PiP Entry:
```
PiP - Recreating pictureInPictureController for new session
PiP - applyCurrentPropertiesToController STARTING:
PiP -   participantName: 'Santhosh Vaiyapuri'
PiP - Controller.participantName didSet: 'Santhosh Vaiyapuri', contentViewController exists: true
PiP - Renderer.participantName didSet: 'Santhosh Vaiyapuri', forwarding to avatarView
PiP - AvatarView.participantName didSet: 'Santhosh Vaiyapuri'
PiP - AvatarView updateInitials: name=Santhosh Vaiyapuri, initials=SV, ...
PiP - applyCurrentPropertiesToController COMPLETED
```

If logs show step 3 (Renderer) but NOT step 4 (AvatarView), then the issue is in how the renderer forwards to avatarView. This could indicate:
- The avatarView reference is stale
- The lazy var is creating a new instance
- Some other initialization timing issue

### Root Cause Found:
The logs revealed that `avatarView.participantName` HAS the correct value, but `updateInitials()` is NEVER called on the second PiP entry. This is because:

1. The RTCViewPip view stays in the hierarchy (never removed from superview)
2. The controller is NOT recreated (same controller reused)
3. React Native doesn't re-send unchanged property values
4. `participantName` didSet doesn't fire (value unchanged)
5. `updateInitials()` is never called on second entry
6. `initialsLabel.text` is still nil from initialization (or from a reset)

### Fixes Applied:

**Fix 1: Refresh content when avatar becomes visible**
Modified `PictureInPictureAvatarView.swift` to call `updateInitials()` when `isVideoEnabled` becomes false:

```swift
var isVideoEnabled: Bool = true {
    didSet {
        updateVisibility()
        if !isVideoEnabled {
            updateInitials()  // Refresh content when becoming visible
        }
    }
}
```

**Fix 2: Force immediate layout after constraint updates**
The avatar container was being positioned for intermediate large bounds (820x1155) instead of the actual PiP window size (264x198). This happened because constraints set during `layoutSubviews` weren't resolved until the next layout pass.

Modified `updateAvatarSize()` to force immediate layout:

```swift
private func updateAvatarSize() {
    NSLayoutConstraint.deactivate(avatarSizeConstraints)
    // ... calculate avatarSize ...
    NSLayoutConstraint.activate(avatarSizeConstraints)

    // Force immediate layout to apply the new constraints
    containerView.setNeedsLayout()
    containerView.layoutIfNeeded()

    // Update corner radius after layout is complete
    avatarContainerView.layer.cornerRadius = avatarContainerView.bounds.width / 2
}
```

### Result:
Avatar now shows correctly on all PiP sessions (first, second, and subsequent entries).

### Note on `applyCurrentPropertiesToController()`:
This function is still needed for the case where RTCViewPip is actually removed from superview and re-added (e.g., navigating away from call screen and back). In normal PiP flow, the view stays in the hierarchy, but for edge cases where it's removed, this function ensures properties are re-applied to the recreated controller.
---

## Iteration 19 - Fix Reconnection View Not Showing When Offline
- **Task Status:** Implemented
- **Verification:** Manual test passed - reconnection view shows when internet is switched off
- **Implementation Details:**
  - `RTCViewPipIOS.tsx:131-135` - Added `CallingState.OFFLINE` to `isReconnecting` check
  - `PictureInPictureReconnectionView.swift` - Replaced spinner with animated dots matching upstream `CallingIndicator`

- **Learnings for future iterations:**
  - Upstream `stream-video-swift` shows reconnection view for BOTH `reconnectionStatus == .reconnecting` AND `!internetConnectionObserver.isAvailable`
  - JS client sets `CallingState.OFFLINE` when internet is unavailable (Call.ts:1696), not `RECONNECTING`
  - `UIView.animate` doesn't work in PiP overlays, but `CABasicAnimation` does
  - SwiftUI animations translate to Core Animation under the hood, so `CABasicAnimation` is the correct UIKit equivalent

### Root Cause:
The reconnection view wasn't showing because the JS check only included `RECONNECTING` and `RECONNECTING_FAILED`, but when internet is switched off, the client sets `CallingState.OFFLINE`.

### Files Modified:

**TypeScript/React:**
1. **RTCViewPipIOS.tsx**
   - Added `CallingState.OFFLINE` to the `isReconnecting` check to match upstream behavior

**Native iOS (Swift):**
2. **PictureInPictureReconnectionView.swift**
   - Replaced `UIActivityIndicatorView` with three pulsing dots matching upstream `CallingIndicator`
   - Dot size: 4pt, spacing: 2pt (matches upstream)
   - Animation uses `CABasicAnimation` with opacity pulse (0 → 1)
   - Timing functions match upstream: `.easeOut`, `.easeInEaseOut`, `.easeIn`
   - Duration: 1 second, delay: 0.2 seconds, autoreverses with infinite repeat

### Upstream Alignment:
| Upstream SwiftUI | Our CABasicAnimation |
|------------------|---------------------|
| `.easeOut(duration: 1)` | `CAMediaTimingFunction(name: .easeOut)`, `duration = 1.0` |
| `.easeInOut(duration: 1)` | `CAMediaTimingFunction(name: .easeInEaseOut)`, `duration = 1.0` |
| `.easeIn(duration: 1)` | `CAMediaTimingFunction(name: .easeIn)`, `duration = 1.0` |
| `.delay(0.2)` | `beginTime = CACurrentMediaTime() + 0.2` |
| `.repeatForever(autoreverses: true)` | `repeatCount = .infinity`, `autoreverses = true` |
| `opacity: 0 → 1` | `fromValue = 0.0`, `toValue = 1.0` |